
@article{koohestani2025agentguard,
  title={AgentGuard: Runtime Verification of AI Agents},
  author={Koohestani, Roham},
  journal={arXiv preprint arXiv:2509.23864},
  year={2025}
}

@article{wang2025agentspec,
  title={Agentspec: Customizable runtime enforcement for safe and reliable llm agents},
  author={Wang, Haoyu and Poskitt, Christopher M and Sun, Jun},
  journal={arXiv preprint arXiv:2503.18666},
  year={2025}
}


@article{wang2025pro2guard,
  title={Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking},
  author={Wang, Haoyu and Poskitt, Chris M and Sun, Jun and Wei, Jiali},
  journal={arXiv preprint arXiv:2508.00500},
  year={2025}
}

@inproceedings{
li2025llm,
title={{LLM} Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet},
author={Nathaniel Li and Ziwen Han and Ian Steneker and Willow E. Primack and Riley Goodside and Hugh Zhang and Zifan Wang and Cristina Menghini and Summer Yue},
booktitle={Red Teaming GenAI: What Can We Learn from Adversaries?},
year={2025},
url={https://openreview.net/forum?id=ZmQX402jWC}
}
@article{zhang2025rvllm,
  title={RvLLM: LLM Runtime Verification with Domain Knowledge},
  author={Zhang, Yedi and Emma, Sun Yi and En, Annabelle Lee Jia and Dong, Jin Song},
  journal={arXiv preprint arXiv:2505.18585},
  year={2025}
}


@article{zhou2024don,
  title={Don't Trust: Verify--Grounding LLM Quantitative Reasoning with Autoformalization},
  author={Zhou, Jin Peng and Staats, Charles and Li, Wenda and Szegedy, Christian and Weinberger, Kilian Q and Wu, Yuhuai},
  journal={arXiv preprint arXiv:2403.18120},
  year={2024}
}

@inproceedings{tang2024minicheck,
  title={MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents},
  author={Tang, Liyan and Laban, Philippe and Durrett, Greg},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={8818--8847},
  year={2024}
}
@article{lu2025alignment,
  title={Alignment and safety in large language models: Safety mechanisms, training paradigms, and emerging challenges},
  author={Lu, Haoran and Fang, Luyang and Zhang, Ruidong and Li, Xinliang and Cai, Jiazhang and Cheng, Huimin and Tang, Lin and Liu, Ziyu and Sun, Zeliang and Wang, Tao and others},
  journal={arXiv preprint arXiv:2507.19672},
  year={2025}
}
@article{su2025survey,
  title={A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents},
  author={Su, Hang and Luo, Jun and Liu, Chang and Yang, Xiao and Zhang, Yichi and Dong, Yinpeng and Zhu, Jun},
  journal={arXiv preprint arXiv:2506.23844},
  year={2025}
}
@article{liu2025generative,
  title={Generative Value Conflicts Reveal LLM Priorities},
  author={Liu, Andy and Ghate, Kshitish and Diab, Mona and Fried, Daniel and Kasirzadeh, Atoosa and Kleiman-Weiner, Max},
  journal={arXiv preprint arXiv:2509.25369},
  year={2025}
}

@article{wu2025staircase,
  title={The Staircase of Ethics: Probing LLM Value Priorities through Multi-Step Induction to Complex Moral Dilemmas},
  author={Wu, Ya and Sheng, Qiang and Wang, Danding and Yang, Guang and Sun, Yifan and Wang, Zhengjia and Bu, Yuyan and Cao, Juan},
  journal={arXiv preprint arXiv:2505.18154},
  year={2025}
}

@inproceedings{cekinel2025multimodal,
  title={Multimodal fact-checking with vision language models: A probing classifier based solution with embedding strategies},
  author={Cekinel, Recep Firat and Karagoz, Pinar and {\c{C}}{\"o}ltekin, {\c{C}}a{\u{g}}r{\i}},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={4622--4633},
  year={2025}
}



@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint, arXiv:1502.04623},
  year={2015},
  url={https://arxiv.org/pdf/1502.04623.pdf}
}

@inproceedings{zhang-etal-2025-iheval,
    title = "{IHE}val: Evaluating Language Models on Following the Instruction Hierarchy",
    author = "Zhang, Zhihan  and
      Li, Shiyang  and
      Zhang, Zixuan  and
      Liu, Xin  and
      Jiang, Haoming  and
      Tang, Xianfeng  and
      Gao, Yifan  and
      Li, Zheng  and
      Wang, Haodong  and
      Tan, Zhaoxuan  and
      Li, Yichuan  and
      Yin, Qingyu  and
      Yin, Bing  and
      Jiang, Meng",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    publisher = "Association for Computational Linguistics",
    pages = "8374--8398",
}





















%%%%%%%%%%%%%  Alignment, instruction references  %%%%%%%%%%%  %%%%%%%%%%%  %%%%%%%%%%%  %%%%%%%%%%%%%%%%%%%%%%




@inproceedings{xie2022an,
title={An Explanation of In-context Learning as Implicit Bayesian Inference},
author={Sang Michael Xie and Aditi Raghunathan and Percy Liang and Tengyu Ma},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=RdJVFCHjUMI}
}


@inproceedings{chiu2025dailydilemmas,
title={DailyDilemmas: Revealing Value Preferences of {LLM}s with Quandaries of Daily Life},
author={Yu Ying Chiu and Liwei Jiang and Yejin Choi},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=PGhiPGBf47}
}

@article{wei2023jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={80079--80110},
  year={2023}
}

@inproceedings{perez2022ignore,
title={Ignore Previous Prompt: Attack Techniques For Language Models},
author={F{\'a}bio Perez and Ian Ribeiro},
booktitle={NeurIPS ML Safety Workshop},
year={2022},
url={https://openreview.net/forum?id=qiaRo_7Zmug}
}


@inproceedings{guo2024large,
  title={Large language model based multi-agents: a survey of progress and challenges},
  author={Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  booktitle={Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence},
  pages={8048--8057},
  year={2024}
}







@article{reinhart2025llms,
author = {Alex Reinhart  and Ben Markey  and Michael Laudenbach  and Kachatad Pantusen  and Ronald Yurko  and Gordon Weinberg  and David West Brown },
title = {Do LLMs write like humans? Variation in grammatical and rhetorical styles},
journal = {Proceedings of the National Academy of Sciences},
year = {2025},
}



@inproceedings{ahn-etal-2024-large,
    title = "Large Language Models for Mathematical Reasoning: Progresses and Challenges",
    author = "Ahn, Janice  and
      Verma, Rishu  and
      Lou, Renze  and
      Liu, Di  and
      Zhang, Rui  and
      Yin, Wenpeng",
    editor = "Falk, Neele  and
      Papi, Sara  and
      Zhang, Mike",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop",
    year = "2024",
}


@book{asimov2004i,
  title={I, robot, volume 1},
  author={Asimov, Isaac},
  year={2004},
  publisher={Spectra}
}


@article{jiang2021can,
  title={Can machines learn morality? the delphi experiment},
  author={Jiang, Liwei and Hwang, Jena D and Bhagavatula, Chandra and Bras, Ronan Le and Liang, Jenny and Dodge, Jesse and Sakaguchi, Keisuke and Forbes, Maxwell and Borchardt, Jon and Gabriel, Saadia and others},
  journal={arXiv preprint arXiv:2110.07574},
  year={2021}
}

@inproceedings{wang2024helpsteer,
title={HelpSteer 2: Open-source dataset for training top-performing reward models},
author={Zhilin Wang and Yi Dong and Olivier Delalleau and Jiaqi Zeng and Gerald Shen and Daniel Egert and Jimmy J. Zhang and Makesh Narsimhan Sreedhar and Oleksii Kuchaiev},
booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2024},
url={https://openreview.net/forum?id=PvVKUFhaNy}
}

@inproceedings{ethayarajh2022understanding,
  title={Understanding Dataset Difficulty with V-Usable Information},
  author={Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle={International Conference on Machine Learning},
  pages={5988--6008},
  year={2022},
  organization={PMLR}
}

@inproceedings{jin2025language,
title={Language Model Alignment in Multilingual Trolley Problems},
author={Zhijing Jin and Max Kleiman-Weiner and Giorgio Piatti and Sydney Levine and Jiarui Liu and Fernando Gonzalez Adauto and Francesco Ortu and Andr{\'a}s Strausz and Mrinmaya Sachan and Rada Mihalcea and Yejin Choi and Bernhard Sch{\"o}lkopf},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=VEqPDZIDAh}
}

@article{hatemo2025revisiting,
  title={Revisiting the Trolley Problem for AI: Biases and Stereotypes in Large Language Models and their Impact on Ethical Decision-Making},
  author={Hatemo, Sahan and Weickhardt, Christof and Gisler, Luca and Bendel, Oliver},
  journal={Proceedings of the AAAI Symposium Series},
  volume={5},
  number={1},
  year={2025}
}

@article{samway2025language,
  title={Are Language Models Consequentialist or Deontological Moral Reasoners?},
  author={Samway, Keenan and Kleiman-Weiner, Max and Piedrahita, David Guzman and Mihalcea, Rada and Sch{\"o}lkopf, Bernhard and Jin, Zhijing},
  journal={arXiv preprint arXiv:2505.21479},
  year={2025}
}

@inproceedings{wu2025aligning,
  title={Aligning LLMs with Individual Preferences via Interaction},
  author={Wu, Shujin and Fung, May and Qian, Cheng and Kim, Jeonghwan and Hakkani-Tur, Dilek and Ji, Heng},
  booktitle={31st International Conference on Computational Linguistics, COLING 2025},
  pages={7648--7662},
  year={2025},
  organization={Association for Computational Linguistics (ACL)}
}



@inproceedings{sharma2024towards,
title={Towards Understanding Sycophancy in Language Models},
author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Duvenaud and Amanda Askell and Samuel R. Bowman and Esin DURMUS and Zac Hatfield-Dodds and Scott R Johnston and Shauna M Kravec and Timothy Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=tvhaxkMKAn}
}


@inproceedings{pan2023rewards,
  title={Do the rewards justify the means? measuring trade-offs between rewards and ethical behavior in the MACHIAVELLI benchmark},
  author={Pan, Alexander and Chan, Jun Shern and Zou, Andy and Li, Nathaniel and Basart, Steven and Woodside, Thomas and Zhang, Hanlin and Emmons, Scott and Hendrycks, Dan},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={26837--26867},
  year={2023}
}

@article{scherrer2023evaluating,
  title={Evaluating the moral beliefs encoded in llms},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={51778--51809},
  year={2023}
}

@inproceedings{perez2023discovering,
  title={Discovering language model behaviors with model-written evaluations},
  author={Perez, Ethan and Ringer, Sam and Lukosiute, Kamile and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13387--13434},
  year={2023}
}


@article{alkaissi2023artificial,
  title={Artificial hallucinations in chatgpt: implications in scientific writing},
  author={Alkaissi, Hussam and McFarlane, Samy I},
  journal={Cureus},
  volume={15},
  number={2},
  year={2023}
}

@article{manakul2023selfcheckgpt,
  title={Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark~JF},
  journal={arXiv preprint arXiv:2303.08896},
  year={2023}
}

@article{jang2023consistency,
  title={Consistency analysis of chatgpt},
  author={Jang, Myeongjun and Lukasiewicz, Thomas},
  journal={arXiv preprint arXiv:2303.06273},
  year={2023}
}

@article{ohmer2023evaluating,
  title={Evaluating task understanding through multilingual consistency: A chatgpt case study},
  author={Ohmer, Xenia and Bruni, Elia and Hupkes, Dieuwke},
  journal={arXiv preprint arXiv:2305.11662},
  year={2023}
}


@article{elazar2021measuring,
  title={Measuring and improving consistency in pretrained language models},
  author={Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Ravichander, Abhilasha and Hovy, Eduard and Sch{\"u}tze, Hinrich and Goldberg, Yoav},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1012--1031},
  year={2021}
}


@article{izacard2022unsupervised,
  title={Unsupervised dense information retrieval with contrastive learning},
  author={Izacard, Gautier and Caron, Mathilde and Hosseini, Lucas and Riedel, Sebastian and Bojanowski, Piotr and Joulin, Armand and Grave, Edouard},
  journal={arXiv preprint arXiv:2202.01332},
  year={2022}
}

@inproceedings{bang2023multitask,
  title={A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity},
  author={Bang, Yejin and others},
  booktitle={ACL},
  year={2023}
}

@article{mallen2022not,
  title={When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories},
  author={Mallen, Alex and Asai, Akari and Zhong, Victor and Das, Rajarshi and Hajishirzi, Hannaneh and Khashabi, Daniel},
  journal={arXiv preprint arXiv:2212.10511},
  year={2022}
}


@article{si2022prompting,
  title={Prompting gpt-3 to be reliable},
  author={Si, Chenglei and Gan, Zhe and Yang, Zhengyuan and Wang, Shuohang and Wang, Jianfeng and Boyd-Graber, Jordan and Wang, Lijuan},
  journal={arXiv preprint arXiv:2210.09150},
  year={2022}
}




@misc{openai2023gpt4,
  title={OpenAI. GPT-4 system card, https://cdn.openai.com/papers/ gpt-4-system-card.pdf. 2023b.}
}

@article{borji2023categorical,
  title={A categorical archive of chatgpt failures},
  author={Borji, Ali},
  journal={arXiv preprint arXiv:2302.03494},
  year={2023}
}
@inproceedings{jalil2023chatgpt,
  title={Chatgpt and software testing education: Promises \& perils},
  author={Jalil, Sajed and Rafi, Suzzana and LaToza, Thomas D and Moran, Kevin and Lam, Wing},
  booktitle={2023 IEEE international conference on software testing, verification and validation workshops (ICSTW)},
  pages={4130--4137},
  year={2023},
  organization={IEEE}
}


@misc{openai2025model,
  title={OpenAI. Model Spec. https://model-spec.openai.com/2025-02-12.html, 2025. Published: 2025-02-12; Accessed: 2025-02-12.},
  year={2025}
}

@misc{anthropic2024claudes,
  title={Anthropic. Claude’s Constitution. https://www.anthropic.com/news/ claudes-constitution, 2024. Published: 2024-05-09; Accessed: 2024-05-19.},
  year={2024}
}

@book{united1949universal,
  title={Universal declaration of human rights},
  author={United Nations. General Assembly},
  volume={3381},
  year={1949},
  publisher={Department of State, United States of America}
}
@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  year={2022}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}


@inproceedings{perez-etal-2023-discovering,
    title = "Discovering Language Model Behaviors with Model-Written Evaluations",
    author = "Perez, Ethan and others",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
}

@inproceedings{wuinstructional,
  title={Instructional Segment Embedding: Improving LLM Safety with Instruction Hierarchy},
  author={Wu, Tong and Zhang, Shujian and Song, Kaiqiang and Xu, Silei and Zhao, Sanqiang and Agrawal, Ravi and Indurthi, Sathish Reddy and Xiang, Chong and Mittal, Prateek and Zhou, Wenxuan},
  booktitle={The Thirteenth International Conference on Learning Representations}
}

@article{shallow2011trolley,
title={Trolley problems in context}, volume={6}, DOI={10.1017/S1930297500002631}, number={7}, journal={Judgment and Decision Making}, author={Shallow, Christopher and Iliev, Rumen and Medin, Douglas}, year={2011}, pages={593–601}
}

@article{greene2015rise,
  title={The rise of moral cognition},
  author={Greene, Joshua D},
  journal={Cognition},
  volume={135},
  pages={39--42},
  year={2015},
  publisher={Elsevier}
}
@article{jerolmack2019ethical,
  title={The ethical dilemmas and social scientific trade-offs of masking in ethnography},
  author={Jerolmack, Colin and Murphy, Alexandra K},
  journal={Sociological Methods \& Research},
  volume={48},
  number={4},
  pages={801--827},
  year={2019},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}


@misc{wallace2025the,
title={The Instruction Hierarchy: Training {LLM}s to Prioritize Privileged Instructions},
author={Eric Wallace and Kai Yuanqing Xiao and Reimar Heinrich Leike and Lilian Weng and Johannes Heidecke and Alex Beutel},
year={2025},
url={https://openreview.net/forum?id=vf5M8YaGPY}
}

@article{shen2023hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={38154--38180},
  year={2023}
}

@inproceedings{yao2023react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}


@inproceedings{schulhoff2023ignore,
  title={Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition},
  author={Schulhoff, Sander and Pinto, Jeremy and Khan, Anaum and Bouchard, Louis-Fran{\c{c}}ois and Si, Chenglei and Anati, Svetlina and Tagliabue, Valen and Kost, Anson and Carnahan, Christopher and Boyd-Graber, Jordan},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={4945--4977},
  year={2023}
}


@article{schick2024toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dessi, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{weng2023llm,
  title={LLM-powered autonomous agents},
  author={Weng, Lilian},
  year={2023},
  url={https://lilianweng.github.io/posts/2023-06-23-agent/}
}


@misc{zhong2024command,
  title={Command injection — OWASP foundation},
  author={Zhong, Weilin and Wichers, Amwestgate and Rezos and Clow and KristenS and Jason Li and Andrew Smith and Jmanico and Tal Mel and kingthorin},
  year={2024},
}

@article{ritchie1974unix,
  title={The UNIX time-sharing system},
  author={Ritchie, Dennis M and Thompson, Ken},
  journal={Communications of the ACM},
  volume={17},
  number={7},
  pages={365--375},
  year={1974},
  publisher={ACM New York, NY, USA}
}


@inproceedings{toyer2024tensor,
title={Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game},
author={Sam Toyer and Olivia Watkins and Ethan Adrian Mendes and Justin Svegliato and Luke Bailey and Tiffany Wang and Isaac Ong and Karim Elmaaroufi and Pieter Abbeel and Trevor Darrell and Alan Ritter and Stuart Russell},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=fsW7wJGLBd}
}



@inproceedings{greshake2023not,
  title={Not what you've signed up for: Compromising real-world llm-integrated applications with indirect prompt injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  booktitle={Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
  pages={79--90},
  year={2023}
}




@inproceedings{shah2023scalable,title={Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation},
author={Rusheb Shah and Quentin Feuillade Montixi and Soroush Pour and Arush Tagade and Javier Rando},
booktitle={Socially Responsible Language Modelling Research},
year={2023},
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}


@article{liu2023prompt,
  title={Prompt Injection attack against LLM-integrated Applications},
  author={Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Wang, Zihao and Wang, Xiaofeng and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and others},
  journal={arXiv preprint arXiv:2306.05499},
  year={2023}
}

@misc{liu2023jailbreaking,
    title        = {{Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study}},
    author       = {Yi Liu and Gelei Deng and Zhengzi Xu and Yuekang Li and Yaowen Zheng and Ying Zhang and Lida Zhao and Tianwei Zhang and Yang Liu},
    year         = {2023},
    eprint       = {2305.13860},
    archiveprefix = {arXiv},
}

@article{jiang2024artprompt,
    title        = {{ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs}},
    author       = {Jiang, Fengqing and Xu, Zhangchen and Niu, Luyao and Xiang, Zhen and Ramasubramanian, Bhaskar and Li, Bo and Poovendran, Radha},
    year         = {2024},
    journal      = {arXiv preprint arXiv:2402.11753}
}
@article{deng2023multilingual,
    title        = {{Multilingual Jailbreak Challenges in Large Language Models}},
    author       = {Deng, Yue and Zhang, Wenxuan and Pan, Sinno Jialin and Bing, Lidong},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2310.06474}
}

@misc{yong2023lowresource,
    title        = {{Low-Resource Languages Jailbreak GPT-4}},
    author       = {Zheng-Xin Yong and Cristina Menghini and Stephen H. Bach},
    year         = {2023},
    eprint       = {2310.02446},
    archiveprefix = {arXiv},
}
@article{bailey2023image,
    title        = {{Image Hijacking: Adversarial Images can Control Generative Models at Runtime}},
    author       = {Bailey, Luke and Ong, Euan and Russell, Stuart and Emmons, Scott},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2309.00236}
}
@article{anil2024manyshot,
    title        = {{Many-shot Jailbreaking}},
    author       = {Anil, Cem and Durmus, Esin and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Rimsky, Nina and Tong, Meg and Mu, Jesse and Ford, Daniel and Mosconi, Francesco and Agrawal, Rajashree and Schaeffer, Rylan and Bashkansky, Naomi and Svenningsen, Samuel and Lambert, Mike and Radhakrishnan, Ansh and Denison, Carson and Hubinger, Evan J and Bai, Yuntao and Bricken, Trenton and Maxwell, Timothy and Schiefer, Nicholas and Sully, Jamie and Tamkin, Alex and Lanham, Tamera and Nguyen, Karina and Korbak, Tomasz and Kaplan, Jared and Ganguli, Deep and Bowman, Samuel R. and Perez, Ethan and Grosse, Roger and Duvenaud, David},
    year         = {2024},
    journal      = {Preprint}
}
@article{shen2023anything,
    title        = {{``Do Anything Now'': Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models}},
    author       = {Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2308.03825}
}
@misc{rao2023tricking,
    title        = {{Tricking LLMs into Disobedience: Understanding, Analyzing, and Preventing Jailbreaks}},
    author       = {Abhinav Rao and Sachin Vashistha and Atharva Naik and Somak Aditya and Monojit Choudhury},
    year         = {2023},
    eprint       = {2305.14965},
    archiveprefix = {arXiv},
}

@article{li2023emotionprompt,
    title        = {{Emotionprompt: Leveraging psychology for large language models enhancement via emotional stimulus}},
    author       = {Li, Cheng and Wang, Jindong and Zhu, Kaijie and Zhang, Yixuan and Hou, Wenxin and Lian, Jianxun and Xie, Xing},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2307.11760}
}
@article{andreas2022language,
    title        = {{Language models as agent models}},
    author       = {Andreas, Jacob},
    year         = {2022},
    journal      = {arXiv preprint arXiv:2212.01681}
}

@article{perez2022red,
    title        = {{Red teaming language models with language models}},
    author       = {Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
    year         = {2022},
    journal      = {arXiv preprint arXiv:2202.03286}
}
@article{casper2023explore,
    title        = {{Explore, Establish, Exploit: Red Teaming Language Models from Scratch}},
    author       = {Casper, Stephen and Lin, Jason and Kwon, Joe and Culp, Gatlen and Hadfield-Menell, Dylan},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2306.09442}
}

@article{anwar2024foundational,
title={Foundational Challenges in Assuring Alignment and Safety of Large Language Models},
author={Usman Anwar and others},
journal={Transactions on Machine Learning Research},
year={2024},
}
@article{zverev2024can,
    title        = {{Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?}},
    author       = {Zverev, Egor and Abdelnabi, Sahar and Fritz, Mario and Lampert, Christoph H},
    year         = {2024},
    journal      = {arXiv preprint arXiv:2403.06833}
}

@article{toyer2023tensor,
    title        = {{Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game}},
    author       = {Toyer, Sam and Watkins, Olivia and Mendes, Ethan Adrian and Svegliato, Justin and Bailey, Luke and Wang, Tiffany and Ong, Isaac and Elmaaroufi, Karim and Abbeel, Pieter and Darrell, Trevor and others},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2311.01011}
}

@article{greshake2023promptinjection,
    title        = {{More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models}},
    author       = {Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2302.12173}
}
@article{zhang2023prompts,
    title        = {{Prompts should not be seen as secrets: Systematically measuring prompt extraction attack success}},
    author       = {Zhang, Yiming and Ippolito, Daphne},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2307.06865}
}
@article{qiang2023hijacking,
    title        = {{Hijacking Large Language Models via Adversarial In-Context Learning}},
    author       = {Qiang, Yao and Zhou, Xiangyu and Zhu, Dongxiao},
    year         = {2023},
    journal      = {arXiv preprint arXiv:2311.09948}
}
@misc{gptengineer,
    title        = {{GPT Engineer}},
    author       = {Anton Osika},
    year         = {2023},
    url          = {https://github.com/AntonOsika/gpt-engineer},
    note         = {Initial release: June 10, 2023}
}

@misc{greshake2023youve,
    title        = {{Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection}},
    author       = {Kai Greshake and Sahar Abdelnabi and Shailesh Mishra and Christoph Endres and Thorsten Holz and Mario Fritz},
    year         = {2023},
    eprint       = {2302.12173},
    archiveprefix = {arXiv},
}


@inproceedings{ilyas2022datamodels,
  title={Datamodels: Predicting Predictions from Training Data},
  author={Ilyas, Andrew and Park, Sung Min and Engstrom, Logan and Leclerc, Guillaume and Madry, Aleksander},
  booktitle={Proceedings of the 39th International Conference on Machine Learning},
  year={2022}
}
@article{yeh2018representer,
  title={Representer point selection for explaining deep neural networks},
  author={Yeh, Chih-Kuan and Kim, Joon and Yen, Ian En-Hsu and Ravikumar, Pradeep K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{grosse2023studying,
  title={Studying large language model generalization with influence functions},
  author={Grosse, Roger and Bae, Juhan and Anil, Cem and Elhage, Nelson and Tamkin, Alex and Tajdini, Amirhossein and Steiner, Benoit and Li, Dustin and Durmus, Esin and Perez, Ethan and others},
  journal={arXiv preprint arXiv:2308.03296},
  year={2023}
}
@inproceedings{liu2023trustworthy,
title={Trustworthy {LLM}s: a Survey and Guideline for Evaluating Large Language Models' Alignment},
author={Yang Liu and Yuanshun Yao and Jean-Francois Ton and Xiaoying Zhang and Ruocheng Guo and Hao Cheng and Yegor Klochkov and Muhammad Faaiz Taufiq and Hang Li},
booktitle={Socially Responsible Language Modelling Research},
year={2023},
url={https://openreview.net/forum?id=oss9uaPFfB}
}



@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@article{ji2023survey,
  title={A survey of hallucination in large language models},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Madotto, Andrea and Cahyawijaya, Samuel and others},
  journal={arXiv preprint arXiv:2305.10766},
  year={2023}
}

@article{zhu2023promptbench,
  title={Promptbench: Towards evaluating the robustness of large language models on adversarial prompts},
  author={Zhu, Kaijie and Zhao, Jindong and Wang, Yidong and Wang, Chaowei},
  journal={arXiv preprint arXiv:2306.04528},
  year={2023}
}

@article{lazaridou2021mind,
  title={Mind the gap: Assessing temporal generalization in neural language models},
  author={Lazaridou, Angeliki and Kuncoro, Adhiguna and Gribovskaya, Elena and Agrawal, Devang and Liska, Adam and Terzi, Tayfun and Gimenez, Mai and d'Autume, Cyprien de Masson and Ruder, Sebastian and Yogatama, Dani and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29348--29363},
  year={2021}
}

@article{carlini2023poisoning,
  title={Poisoning web-scale training datasets is practical},
  author={Carlini, Nicholas and Li, Meng and Pruthi, Danish and Wallace, Eric and Jia, Robin and Steinhardt, Jacob and Tramer, Florian},
  journal={arXiv preprint arXiv:2302.10149},
  year={2023}
}

@inproceedings{bowman2023eight,
  title={Eight things to know about large language models},
  author={Bowman, Samuel R},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1--14},
  year={2023}
}

@article{dark,
  title={The dark side of large language models},
  author={Wickens, Eoin and Janus, Marta},
  journal={https://hiddenlayer.com/research/the-dark-side-of-large-language-models/},
  year={2023}
}

@article{oviedo2023risks,
  title={The risks of using chatgpt to obtain common safety-related information and advice},
  author={Oviedo-Trespalacios, Oscar and Peden, Amy~E and Cole-Hunter, Thomas and Costantini, Arianna and Haghani, Milad and Kelly, Sage and Torkamaan, Helma and Tariq, Amina and Newton, James David and Gallagher, Timothy and others},
  journal={Available at SSRN 4346827},
  year={2023}
}
@article{oswell1999dark,
  title={The dark side of cyberspace: Internet content regulation and child protection},
  author={Oswell, David},
  journal={Convergence},
  volume={5},
  number={4},
  year={1999}
}

@article{carr2009child,
  title={Child protection and self-regulation in the internet industry: The uk experience},
  author={Carr, John and Hilton, Zoe},
  journal={Children \& society},
  volume={23},
  number={4},
  year={2009}
}

@article{akdeniz1997regulation,
  title={Regulation of the internet: A review of the literature},
  author={Akdeniz, Omer},
  journal={Telematics and Informatics},
  volume={13},
  number={4},
  year={1997}
}


@article{zhang2023multimodal,
  title={Multimodal chain-of-thought reasoning in language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal={arXiv preprint arXiv:2302.00923},
  year={2023}
}

@article{kandpal2022deduplicating,
  title={Deduplicating training data mitigates privacy risks in language models},
  author={Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
  journal={arXiv preprint arXiv:2203.00295},
  year={2022},
}
@inproceedings{
ye2024justice,
title={Justice or Prejudice? Quantifying Biases in {LLM}-as-a-Judge},
author={Jiayi Ye and Yanbo Wang and Yue Huang and Dongping Chen and Qihui Zhang and Nuno Moniz and Tian Gao and Werner Geyer and Chao Huang and Pin-Yu Chen and Nitesh V Chawla and Xiangliang Zhang},
booktitle={Neurips Safe Generative AI Workshop 2024},
year={2024},
url={https://openreview.net/forum?id=wtscPS2zJH}
}




@article{durmus2024measuring,
  title={Measuring the persuasiveness of language models},
  author={Durmus, Esin and Lovitt, Liane and Tamkin, Alex and Ritchie, Stuart and Clark, Jack and Ganguli, Deep},
  year={2024},
  journal={URL https://www.anthropic.com/news/measuring-model-persuasiveness}
}


@article{rogiers2024persuasion,
  title={Persuasion with Large Language Models: a Survey},
  author={Rogiers, Alexander and Noels, Sander and Buyl, Maarten and De Bie, Tijl},
  year={2024},
  journal={CoRR},
  volume={abs/2411.06837},
  url={https://doi.org/10.48550/arXiv.2411.06837}
}


@inproceedings{jin2024persuading,
  title={Persuading across Diverse Domains: a Dataset and Persuasion Large Language Model},
  author={Jin, Chuhao and Ren, Kening and Kong, Lingzhen and Wang, Xiting and Song, Ruihua and Chen, Huan},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1678--1706},
  year={2024}
}


@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{chen2024humans,
  title={Humans or llms as the judge? a study on judgement biases},
  author={Chen, Guiming Hardy and Chen, Shunian and Liu, Ziche and Jiang, Feng and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.10669},
  year={2024}
}

@inproceedings{wang2024large,
  title={Large Language Models are not Fair Evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Kong, Lingpeng and Liu, Qi and Liu, Tianyu and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9440--9450},
  year={2024}
}
@article{stureborg2024large,
  title={Large language models are inconsistent and biased evaluators},
  author={Stureborg, Rickard and Alikaniotis, Dimitris and Suhara, Yoshi},
  journal={arXiv preprint arXiv:2405.01724},
  year={2024},
}









%%%%%%%%%%%%%   Value alignment   %%%%%%%%%%%  %%%%%%%%%%%  %%%%%%%%%%%  %%%%%%%%%%%%%%%%%%%%%%




@article{asimov1950three,
  title={Three laws of robotics},
  author={Asimov, Isaac},
  year={1950}
}

@InProceedings{pmlr-v235-huh24a,
  title = 	 {Position: The Platonic Representation Hypothesis},
  author =       {Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {20617--20642},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
}



@inproceedings{kang-etal-2025-values,
    title = "Are the Values of {LLM}s Structurally Aligned with Humans? A Causal Perspective",
    author = "Kang, Yipeng  and
      Wang, Junqi  and
      Li, Yexin  and
      Wang, Mengmeng  and
      Tu, Wenming  and
      Wang, Quansen  and
      Li, Hengli  and
      Wu, Tingjun  and
      Feng, Xue  and
      Zhong, Fangwei  and
      Zheng, Zilong",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.1188/",
    doi = "10.18653/v1/2025.findings-acl.1188",
    pages = "23147--23161",
}


@inproceedings{jiang2024can,
title={Can Language Models Reason about Individualistic Human Values and Preferences?},
author={Liwei Jiang and Sydney Levine and Yejin Choi},
booktitle={Pluralistic Alignment Workshop at NeurIPS 2024},
year={2024},
url={https://openreview.net/forum?id=VUq1dDJBf0}
}


@inproceedings{sorensen2024value,
  title={Value kaleidoscope: Engaging ai with pluralistic human values, rights, and duties},
  author={Sorensen, Taylor and Jiang, Liwei and Hwang, Jena D and Levine, Sydney and Pyatkin, Valentina and West, Peter and Dziri, Nouha and Lu, Ximing and Rao, Kavel and Bhagavatula, Chandra and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={18},
  pages={19937--19947},
  year={2024}
}

@article{pathak2025rubric,
  title={Rubric is all you need: Enhancing llm-based code evaluation with question-specific rubrics},
  author={Pathak, Aditya and Gandhi, Rachit and Uttam, Vaibhav and Ramamoorthy, Arnav and Ghosh, Pratyush and Jindal, Aaryan Raj and Verma, Shreyash and Mittal, Aditya and Ased, Aashna and Khatri, Chirag and others},
  journal={arXiv preprint arXiv:2503.23989},
  year={2025}
}
@article{huang2025reinforcement,
  title={Reinforcement Learning with Rubric Anchors},
  author={Huang, Zenan and Zhuang, Yihong and Lu, Guoshan and Qin, Zeyu and Xu, Haokai and Zhao, Tianyu and Peng, Ru and Hu, Jiaqi and Shen, Zhanming and Hu, Xiaomeng and others},
  journal={arXiv preprint arXiv:2508.12790},
  year={2025}
}

@article{chen2025harnessing,
  title={Harnessing multiple large language models: A survey on llm ensemble},
  author={Chen, Zhijun and Li, Jingzheng and Chen, Pengpeng and Li, Zhuoran and Sun, Kai and Luo, Yuankai and Mao, Qianren and Yang, Dingqi and Sun, Hailong and Yu, Philip S},
  journal={arXiv preprint arXiv:2502.18036},
  year={2025}
}
@article{huang2024ensemble,
  title={Ensemble learning for heterogeneous large language models with deep parallel collaboration},
  author={Huang, Yichong and Feng, Xiaocheng and Li, Baohang and Xiang, Yang and Wang, Hui and Liu, Ting and Qin, Bing},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={119838--119860},
  year={2024}
}



@article{mallinar2025scalable,
  title={A Scalable Framework for Evaluating Health Language Models},
  author={Mallinar, Neil and Heydari, A Ali and Liu, Xin and Faranesh, Anthony Z and Winslow, Brent and Hammerquist, Nova and Graef, Benjamin and Speed, Cathy and Malhotra, Mark and Patel, Shwetak and others},
  journal={arXiv preprint arXiv:2503.23339},
  year={2025}
}

@inproceedings{hashemi-etal-2024-llm,
    title = "{LLM}-Rubric: A Multidimensional, Calibrated Approach to Automated Evaluation of Natural Language Texts",
    author = "Hashemi, Helia  and
      Eisner, Jason  and
      Rosset, Corby  and
      Van Durme, Benjamin  and
      Kedzie, Chris",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "13806--13834",
}


@inproceedings{chiudailydilemmas,
  title={DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life},
  author={Chiu, Yu Ying and Jiang, Liwei and Choi, Yejin},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
@article{hubinger2024sleeper,
  title={Sleeper agents: Training deceptive llms that persist through safety training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M and Maxwell, Tim and Cheng, Newton and others},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}
@article{hendrycks2023overview,
  title={An overview of catastrophic AI risks},
  author={Hendrycks, Dan and Mazeika, Mantas and Woodside, Thomas},
  journal={arXiv preprint arXiv:2306.12001},
  year={2023}
}

@article{Kova__2024,
   title={Stick to your role! Stability of personal values expressed in large language models},
   volume={19},
   ISSN={1932-6203},
   url={http://dx.doi.org/10.1371/journal.pone.0309114},
   DOI={10.1371/journal.pone.0309114},
   number={8},
   journal={PLOS ONE},
   publisher={Public Library of Science (PLoS)},
   author={Kovač, Grgur and Portelas, Rémy and Sawayama, Masataka and Dominey, Peter Ford and Oudeyer, Pierre-Yves},
   editor={Zhou, Jingya},
   year={2024},
   month=aug, 
}

@article{moore2024large,
  title={Are Large Language Models Consistent over Value-laden Questions?},
  author={Moore, Jared and Deshpande, Tanvi and Yang, Diyi},
  journal={arXiv preprint arXiv:2407.02996},
  year={2024}
}
@article{Schwartz2012AnOO,
  title={An Overview of the Schwartz Theory of Basic Values},
  author={Shalom H. Schwartz},
  journal={Online Readings in Psychology and Culture},
  year={2012},
  volume={2},
  pages={11},
  url={https://api.semanticscholar.org/CorpusID:16094717}
}
@BOOK{Haidt2012-gu,
  title     = "The righteous mind",
  author    = "Haidt, Jonathan",
  publisher = "Random House",
  month     =  mar,
  year      =  2012,
  address   = "New York, NY"
}
@article{greenblatt2024alignment,
  title={Alignment faking in large language models},
  author={Greenblatt, Ryan and Denison, Carson and Wright, Benjamin and Roger, Fabien and MacDiarmid, Monte and Marks, Sam and Treutlein, Johannes and Belonax, Tim and Chen, Jack and Duvenaud, David and others},
  journal={arXiv preprint arXiv:2412.14093},
  year={2024}
}
@article{bondarenko2025demonstrating,
  title={Demonstrating specification gaming in reasoning models},
  author={Bondarenko, Alexander and Volk, Denis and Volkov, Dmitrii and Ladish, Jeffrey},
  journal={arXiv preprint arXiv:2502.13295},
  year={2025}
}
@article{chen2023combating,
  title={Combating misinformation in the age of llms: Opportunities and challenges},
  author={Chen, Canyu and Shu, Kai},
  journal={arXiv preprint arXiv:2311.05656},
  year={2023}
}
@article{fischer2023what,
  author = {Fischer, Ronald and Luczak-Roesch, Markus and Karl, Johannes A},
  year = {2023},
  title = {What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory},
  journal = {arXiv preprint},
}
@misc{lindahl2023unveiling,
  title={Unveiling the Values of {ChatGPT}: An Explorative Study on Human Values in {AI} Systems},
  author={Lindahl, Caroline and Saeid, Helin},
  year={2023},
  type = {Dissertation},
}

@article{miotto2022gpt,
  title={Who is {GPT}-3? An exploration of personality, values and demographics},
  author={Miotto, Maril{\`u} and Rossberg, Nicola and Kleinberg, Bennett},
  journal={arXiv},
  year={2022},
}
@inproceedings{ScherrerSFB23,
  author       = {Nino Scherrer and
                  Claudia Shi and
                  Amir Feder and
                  David M. Blei},
  title        = {Evaluating the Moral Beliefs Encoded in LLMs},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
}

@article{hadar2024assessing,
  title={Assessing the Alignment of Large Language Models With Human Values for Mental Health Integration: Cross-Sectional Study Using Schwartz’s Theory of Basic Values},
  author={Hadar-Shoval, Dorit and Asraf, Kfir and Mizrachi, Yonathan and Haber, Yuval and Elyoseph, Zohar},
  journal={JMIR Mental Health},
  volume={11},
  year={2024},
}
@article{kovavc2023large,
  title={Large language models as superpositions of cultural perspectives},
  author={Kova{\v{c}}, Grgur and Sawayama, Masataka and Portelas, R{\'e}my and Colas, C{\'e}dric and Dominey, Peter Ford and Oudeyer, Pierre-Yves},
  journal={arXiv preprint arXiv:2307.07870},
  year={2023},
}
@article{wang2024incharacter,
  title={InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews},
  author={Xintao Wang and Yunze Xiao and Jen-tse Huang and Siyu Yuan and Rui Xu and Haoran Guo and Quan Tu and Yaying Fei and Ziang Leng and Wei Wang and Jiangjie Chen and Cheng Li and Yanghua Xiao},
  journal={arXiv preprint arXiv:2310.17976},
  year={2024}
}


@article{zeng2024air,
  title={Air-bench 2024: A safety benchmark based on risk categories from regulations and policies},
  author={Zeng, Yi and Yang, Yu and Zhou, Andy and Tan, Jeffrey Ziwei and Tu, Yuheng and Mai, Yifan and Klyman, Kevin and Pan, Minzhou and Jia, Ruoxi and Song, Dawn and others},
  journal={arXiv preprint arXiv:2407.17436},
  year={2024}
}
@article{carlsmith2022power,
  title={Is power-seeking AI an existential risk?},
  author={Carlsmith, Joseph},
  journal={arXiv preprint arXiv:2206.13353},
  year={2022}
}
@article{chiu2024dailydilemmas,
  title={Dailydilemmas: Revealing value preferences of llms with quandaries of daily life},
  author={Chiu, Yu Ying and Jiang, Liwei and Choi, Yejin},
  journal={arXiv preprint arXiv:2410.02683},
  year={2024}
}
@inproceedings{perez2023discovering,
  title={Discovering language model behaviors with model-written evaluations},
  author={Perez, Ethan and Ringer, Sam and Lukosiute, Kamile and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13387--13434},
  year={2023}
}
@article{mazeika2024harmbench,
  title={Harmbench: A standardized evaluation framework for automated red teaming and robust refusal},
  author={Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and others},
  journal={arXiv preprint arXiv:2402.04249},
  year={2024}
}



@article{pakizeh2007basic,
  title={Basic human values: Inter-value structure in memory},
  author={Pakizeh, Ali and Gebauer, Jochen E and Maio, Gregory R},
  journal={Journal of Experimental Social Psychology},
  volume={43},
  number={3},
  pages={458--465},
  year={2007},
  publisher={Elsevier},
  doi={10.1016/j.jesp.2006.04.007},
}
@article{skimina2021traits,
  title={Traits and values as predictors of the frequency of everyday behavior: Comparison between models and levels},
  author={Skimina, Ewa and Cieciuch, Jan and Strus, W{\l}odzimierz},
  journal={Current Psychology},
  volume={40},
  number={1},
  pages={133--153},
  year={2021},
  publisher={Springer},
  doi={10.1007/s12144-018-9892-9},
}




@article{chiu2025will,
  title={Will AI Tell Lies to Save Sick Children? Litmus-Testing AI Values Prioritization with AIRiskDilemmas},
  author={Chiu, Yu Ying and Wang, Zhilin and Maiya, Sharan and Choi, Yejin and Fish, Kyle and Levine, Sydney and Hubinger, Evan},
  journal={arXiv preprint arXiv:2505.14633},
  year={2025}
}
@article{schwartz2012overview,
  title={An overview of the {S}chwartz theory of basic values},
  author={Schwartz, Shalom H},
  journal={Online readings in Psychology and Culture},
  volume={2},
  number={1},
  pages={1--20},
  year={2012},
  doi={10.9707/2307-0919.1116}
}
@incollection{schwartz1992universals,
  title={Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries},
  author={Schwartz, Shalom H},
  booktitle={Advances in experimental social psychology},
  volume={25},
  pages={1--65},
  year={1992},
  publisher={Elsevier}
}

@article{sagiv2022personal,
  title={Personal values across cultures},
  author={Sagiv, Lilach and Schwartz, Shalom H},
  journal={Annual review of psychology},
  volume={73},
  number={1},
  pages={517--546},
  year={2022},
  publisher={Annual Reviews},
  doi = {10.1146/annurev-psych-020821-125100}
}
@article{schwartz2001value,
  title={Value hierarchies across cultures: Taking a similarities perspective},
  author={Schwartz, Shalom H and Bardi, Anat},
  journal={Journal of cross-cultural Psychology},
  volume={32},
  number={3},
  pages={268--290},
  year={2001},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA},
  doi= {10.1177/0022022101032003002}
}
@article{skimina2021between,
  title={Between-and within-person structures of value traits and value states: Four different structures, four different interpretations},
  author={Skimina, Ewa and Cieciuch, Jan and Revelle, William},
  journal={Journal of Personality},
  volume={89},
  number={5},
  pages={951--969},
  year={2021},
  publisher={Wiley Online Library}
}
@article{daniel2023development,
  title={Development of intraindividual value structures in middle childhood: A multicultural and longitudinal investigation},
  author={Daniel, Ella and D{\"o}ring, Anna K and Cieciuch, Jan},
  journal={Journal of Personality},
  volume={91},
  number={2},
  pages={482--496},
  year={2023},
  publisher={Wiley Online Library}
}
@article{schwartz2022measuring,
  title={Measuring the refined theory of individual values in 49 cultural groups: psychometrics of the revised portrait value questionnaire},
  author={Schwartz, Shalom H and Cieciuch, Jan},
  journal={Assessment},
  volume={29},
  number={5},
  pages={1005--1019},
  year={2022},
  publisher={Sage Publications Sage CA: Los Angeles, CA},
  doi={10.1177/1073191121998760},
}
@inproceedings{aher2023using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={Proceedings of Machine Learning Research}
}

@article{argyle2023out,
  title={Out of one, many: Using language models to simulate human samples},
  author={Argyle, Lisa P and Busby, Ethan C and Fulda, Nancy and Gubler, Joshua R and Rytting, Christopher and Wingate, David},
  journal={Political Analysis},
  volume={31},
  number={3},
  pages={337--351},
  year={2023},
  publisher={Cambridge University Press},
}
@article{safdari2023personality,
  title={Personality traits in large language models},
  author={Safdari, Mustafa and Serapio-Garc{\'\i}a, Greg and Crepy, Cl{\'e}ment and Fitz, Stephen and Romero, Peter and Sun, Luning and Abdulhai, Marwa and Faust, Aleksandra and Matari{\'c}, Maja},
  journal={arXiv preprint arXiv:2307.00184},
  year={2023}
}
@article{stevenson2022putting,
  title={Putting GPT-3's creativity to the (alternative uses) test},
  author={Stevenson, Claire and Smal, Iris and Baas, Matthijs and Grasman, Raoul and van der Maas, Han},
  journal={arXiv preprint arXiv:2206.08932},
  year={2022}
}
@article{deshpande2023toxicity,
  author = {Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
  year = {2023},
  title = {Toxicity in chatgpt: Analyzing persona-assigned language models},
  journal = {arXiv preprint},
  eprint = {2304.05335},
}

@article{li2023theory,
  title={Theory of mind for multi-agent collaboration via large language models},
  author={Li, Huao and Chong, Yu Quan and Stepputtis, Simon and Campbell, Joseph and Hughes, Dana and Lewis, Michael and Sycara, Katia},
  journal={arXiv preprint arXiv:2310.10701},
  year={2023}
}
@article{binz2023using,
  title={Using cognitive psychology to understand GPT-3},
  author={Binz, Marcel and Schulz, Eric},
  journal={Proceedings of the National Academy of Sciences},
  volume={120},
  number={6},
  year={2023},
  publisher={National Acad Sciences},
  doi = {10.1073/pnas.2218523120},
}

@article{roberts2022personality,
  author = {Roberts, Brent W and Yoon, Hee J},
  year = {2022},
  title = {Personality psychology},
  journal = {Annual Review of Psychology},
  volume = {73},
  number = {1},
  pages = {489--516},
  doi = {10.1146/annurev-psych-020821-114927},
}



@misc{serapio2023personality,
      title={Personality Traits in Large Language Models}, 
      author={Greg Serapio-García and Mustafa Safdari and Clément Crepy and Luning Sun and Stephen Fitz and Peter Romero and Marwa Abdulhai and Aleksandra Faust and Maja Matarić},
      year={2025},
      eprint={2307.00184},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.00184}, 
}

@article{pellert2024ai,
  title={Ai psychometrics: Assessing the psychological profiles of large language models through psychometric inventories},
  author={Pellert, Max and Lechner, Clemens M and Wagner, Claudia and Rammstedt, Beatrice and Strohmaier, Markus},
  journal={Perspectives on Psychological Science},
  volume={19},
  number={5},
  pages={808--826},
  year={2024},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{mazeika2025utility,
  title={Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs},
  author={Mazeika, Mantas and Yin, Xuwang and Tamirisa, Rishub and Lim, Jaehyuk and Lee, Bruce W and Ren, Richard and Phan, Long and Mu, Norman and Khoja, Adam and Zhang, Oliver and others},
  journal={arXiv preprint arXiv:2502.08640},
  year={2025}
}
@misc{lee2025promptingfailsswayinertia,
      title={When Prompting Fails to Sway: Inertia in Moral and Value Judgments of Large Language Models}, 
      author={Bruce W. Lee and Yeongheon Lee and Hyunsoo Cho},
      year={2025},
      eprint={2408.09049},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.09049}, 
}
@article{de2021stated,
  title={Stated versus revealed preferences: An approach to reduce bias},
  author={De Corte, Kaat and Cairns, John and Grieve, Richard},
  journal={Health economics},
  volume={30},
  number={5},
  pages={1095--1123},
  year={2021},
  publisher={Wiley Online Library}
}

@article{validity_predictive,
author = {Eastwick, Paul and Sparks, Jehan and Finkel, Eli and Meza, Eva and Adamkovič, Matúš and Ai, Ting and Akintola, Aderonke and Al-Shawaf, Laith and Apriliawati, Denisa and Arriaga, Patricia and Aubert-Teillaud, Benjamin and Baník, Gabriel and Barzykowski, Krystian and Röer, Jan and Ropovik, Ivan and Ross, Robert and Sakman, Ezgi and Salvador, Cristina and Grigoryev, Dmitry},
year = {2024},
month = {07},
pages = {},
title = {A Worldwide Test of the Predictive Validity of Ideal Partner Preference-Matching},
journal = {Journal of Personality and Social Psychology}
}
@article{Teh2023,
  title = {Measuring social desirability bias in a multi-ethnic cohort sample: its relationship with self-reported physical activity,  dietary habits,  and factor structure},
  volume = {23},
  ISSN = {1471-2458},
  url = {http://dx.doi.org/10.1186/s12889-023-15309-3},
  DOI = {10.1186/s12889-023-15309-3},
  number = {1},
  journal = {BMC Public Health},
  publisher = {Springer Science and Business Media LLC},
  author = {Teh,  Wen Lin and Abdin,  Edimansyah and P.V.,  Asharani and Siva Kumar,  Fiona Devi and Roystonn,  Kumarasan and Wang,  Peizhi and Shafie,  Saleha and Chang,  Sherilyn and Jeyagurunathan,  Anitha and Vaingankar,  Janhavi Ajit and Sum,  Chee Fang and Lee,  Eng Sing and van Dam,  Rob M. and Subramaniam,  Mythily},
  year = {2023},
  month = mar 
}

@misc{salecha2024largelanguagemodelshumanlike,
      title={Large Language Models Show Human-like Social Desirability Biases in Survey Responses}, 
      author={Aadesh Salecha and Molly E. Ireland and Shashanka Subrahmanya and João Sedoc and Lyle H. Ungar and Johannes C. Eichstaedt},
      year={2024},
      eprint={2405.06058},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.06058}, 
}
@article{weidinger2023using,
  title={Using the Veil of Ignorance to align AI systems with principles of justice},
  author={Weidinger, Laura and McKee, Kevin R and Everett, Richard and Huang, Saffron and Zhu, Tina O and Chadwick, Martin J and Summerfield, Christopher and Gabriel, Iason},
  journal={Proceedings of the National Academy of Sciences},
  volume={120},
  number={18},
  pages={e2213709120},
  year={2023},
  publisher={National Academy of Sciences}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@inproceedings{
kirk2024the,
title={The {PRISM} Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models},
author={Hannah Rose Kirk and Alexander Whitefield and Paul R{\"o}ttger and Andrew Michael Bean and Katerina Margatina and Rafael Mosquera and Juan Manuel Ciro and Max Bartolo and Adina Williams and He He and Bertie Vidgen and Scott A. Hale},
booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2024},
url={https://openreview.net/forum?id=DFr5hteojx}
}


@article{huang2025values,
  title={Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions},
  author={Huang, Saffron and Durmus, Esin and McCain, Miles and Handa, Kunal and Tamkin, Alex and Hong, Jerry and Stern, Michael and Somani, Arushi and Zhang, Xiuruo and Ganguli, Deep},
  journal={arXiv preprint arXiv:2504.15236},
  year={2025}
}
@article{kirk2024prism,
  title={The prism alignment project: What participatory, representative and individualised human feedback reveals about the subjective and multicultural alignment of large language models},
  author={Kirk, Hannah Rose and Whitefield, Alexander and R{\"o}ttger, Paul and Bean, Andrew and Margatina, Katerina and Ciro, Juan and Mosquera, Rafael and Bartolo, Max and Williams, Adina and He, He and others},
  journal={arXiv preprint arXiv:2404.16019},
  year={2024}
}
@inproceedings{
rozen2025do,
title={Do {LLM}s have Consistent Values?},
author={Naama Rozen and Liat Bezalel and Gal Elidan and Amir Globerson and Ella Daniel},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=8zxGruuzr9}
}
@misc{durmus2024measuringrepresentationsubjectiveglobal,
      title={Towards Measuring the Representation of Subjective Global Opinions in Language Models}, 
      author={Esin Durmus and Karina Nguyen and Thomas I. Liao and Nicholas Schiefer and Amanda Askell and Anton Bakhtin and Carol Chen and Zac Hatfield-Dodds and Danny Hernandez and Nicholas Joseph and Liane Lovitt and Sam McCandlish and Orowa Sikder and Alex Tamkin and Janel Thamkul and Jared Kaplan and Jack Clark and Deep Ganguli},
      year={2024},
      eprint={2306.16388},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.16388}, 
}


@article{xu2023earth,
  title={The earth is flat because...: Investigating llms' belief towards misinformation via persuasive conversation},
  author={Xu, Rongwu and Lin, Brian S and Yang, Shujian and Zhang, Tianqi and Shi, Weiyan and Zhang, Tianwei and Fang, Zhixuan and Xu, Wei and Qiu, Han},
  journal={arXiv preprint arXiv:2312.09085},
  year={2023}
}


























@article{ZWKF23,
  author = {Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
  title = {{Universal and Transferable Adversarial Attacks on Aligned Language Models}},
  journal = {arxiv},
  year = {2023},
  eprint = {2307.15043},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{Yao_2024,
  author = {Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang},
  title = {A survey on large language model (llm) security and privacy: The good, the bad, and the ugly},
  journal = {High-Confidence Computing},
  volume = {4},
  number = {2},
  pages = {100211},
  month = {jun},
  year = {2024}
}

@article{GAAPP23,
  author = {Maanak Gupta and Charankumar Akiri and Kshitiz Aryal and Eli Parker and Lopamudra Praharaj},
  title = {{From ChatGPT to ThreatGPT: Impact of Generative {AI} in Cybersecurity and Privacy}},
  journal = {arxiv},
  year = {2023},
  eprint = {2307.00691},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@inproceedings{SAN23,
  author = {Sonali Singh and Faranak Abri and Akbar Siami Namin},
  title = {{Exploiting Large Language Models (LLMs) through Deception Techniques and Persuasion Principles}},
  booktitle = {{IEEE} International Conference on Big Data (ICBD)},
  pages = {2508--2517},
  publisher = {IEEE},
  year = {2023}
}

@article{ZZLGWLZQS24,
  author = {Zaibin Zhang and Yongting Zhang and Lijun Li and Hongzhi Gao and Lijun Wang and Huchuan Lu and Feng Zhao and Yu Qiao and Jing Shao},
  title = {{PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety}},
  journal = {arxiv},
  year = {2024},
  eprint = {2401.11880},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}

@article{ZWKF23,
  author = {Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
  title = {{Universal and Transferable Adversarial Attacks on Aligned Language Models}},
  journal = {arxiv},
  year = {2023},
  eprint = {2307.15043},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@inproceedings{JDRS23,
  author = {Erik Jones and Anca D. Dragan and Aditi Raghunathan and Jacob Steinhardt},
  title = {{Automatically Auditing Large Language Models via Discrete Optimization}},
  booktitle = {{International Conference on Machine Learning (ICML)}},
  pages = {15307--15329},
  publisher = {PMLR},
  year = {2023}
}

@article{ZZAWBWHNS23,
  author = {Sicheng Zhu and Ruiyi Zhang and Bang An and Gang Wu and Joe Barrow and Zichao Wang and Furong Huang and Ani Nenkova and Tong Sun},
  title = {{AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models}},
  journal = {arxiv},
  year = {2023},
  eprint = {2310.15140},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{wang2024noise,
  author = {Hao Wang and Hao Li and Minlie Huang and Lei Sha},
  title = {{From Noise to Clarity: Unraveling the Adversarial Suffix of Large Language Model Attacks via Translation of Text Embeddings}},
  journal = {arxiv},
  year = {2024},
  eprint = {2402.16006},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@article{geisler2024attacking,
  author = {Simon Geisler and Tom Wollschl{\"a}ger and M. H. I. Abdalla and Johannes Gasteiger and Stephan G{\"u}nnemann},
  title = {{Attacking Large Language Models with Projected Gradient Descent}},
  journal = {arxiv},
  year = {2024},
  eprint = {2402.09154},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{ZSTCZ23,
  author = {Zhuo Zhang and Guangyu Shen and Guanhong Tao and Siyuan Cheng and Xiangyu Zhang},
  title = {{Make Them Spill the Beans! Coercive Knowledge Extraction from (Production) LLMs}},
  journal = {arxiv},
  year = {2023},
  eprint = {2312.04782},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@inproceedings{HGXLC24,
  author = {Yangsibo Huang and Samyak Gupta and Mengzhou Xia and Kai Li and Danqi Chen},
  title = {{Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation}},
  booktitle = {{International Conference on Learning Representations (ICLR)}},
  year = {2024}
}

@article{ZW24,
  author = {Yukai Zhou and Wenjie Wang},
  title = {{Don't Say No: Jailbreaking {LLM} by Suppressing Refusal}},
  journal = {arxiv},
  year = {2024},
  eprint = {2404.16369},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}

@article{qi2023finetuning,
  author = {Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
  title = {Fine-tuning aligned language models compromises safety, even when users do not intend to!},
  journal = {arxiv},
  year = {2023},
  eprint = {2310.03693},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{yang2023shadow,
  author = {Xianjun Yang and Xiao Wang and Qi Zhang and Linda R. Petzold and William Yang Wang and Xun Zhao and Dahua Lin},
  title = {{Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models}},
  journal = {arxiv},
  year = {2023},
  eprint = {2310.02949},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{lermen2023lora,
  author = {Simon Lermen and Charlie Rogers-Smith and Jeffrey Ladish},
  title = {Lora fine-tuning efficiently undoes safety training in llama 2-chat 70b},
  journal = {arxiv},
  year = {2023},
  eprint = {2310.20624},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{zhan2024removing,
  author = {Qiusi Zhan and Richard Fang and Rohan Bindu and Akul Gupta and Tatsunori Hashimoto and Daniel Kang},
  title = {{Removing {RLHF} Protections in {GPT-4} via Fine-Tuning}},
  journal = {arxiv},
  year = {2023},
  eprint = {2311.05553},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}
@article{wu2024you,
  title={You Know What I'm Saying: Jailbreak Attack via Implicit Reference},
  author={Wu, Tianyu and Mei, Lingrui and Yuan, Ruibin and Li, Lujun and Xue, Wei and Guo, Yike},
  journal={arXiv preprint arXiv:2410.03857},
  year={2024}
}
@article{wu2025geneshift,
  title={Geneshift: Impact of different scenario shift on Jailbreaking LLM},
  author={Wu, Tianyi and Xue, Zhiwei and Liu, Yue and Zhang, Jiaheng and Hooi, Bryan and Ng, See-Kiong},
  journal={arXiv preprint arXiv:2504.08104},
  year={2025}
}

@article{LZZYLH23,
  author = {Xuan Li and Zhanke Zhou and Jianing Zhu and Jiangchao Yao and Tongliang Liu and Bo Han},
  title = {{DeepInception: Hypnotize Large Language Model to Be Jailbreaker}},
  journal = {arxiv},
  year = {2023},
  eprint = {2311.03191},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@article{DKMCXCH23,
  author = {Peng Ding and Jun Kuang and Dan Ma and Xuezhi Cao and Yunsen Xian and Jiajun Chen and Shujian Huang},
  title = {{A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily}},
  journal = {arxiv},
  year = {2023},
  eprint = {2311.08268},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@article{WWW23,
  author = {Zeming Wei and Yifei Wang and Yisen Wang},
  title = {{Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations}},
  journal = {arxiv},
  year = {2023},
  eprint = {2310.06387},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG}
}

@article{deng2024pandora,
  author = {Gelei Deng and Yi Liu and Kailong Wang and Yuekang Li and Tianwei Zhang and Yang Liu},
  title = {{Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning}},
  journal = {arxiv},
  year = {2024},
  eprint = {2402.08416},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@misc{many-shots,
  author = {Anthropic},
  title = {Many-shot jailbreaking},
  howpublished = {\url{https://www.anthropic.com/research/many-shot-jailbreaking}},
  year = {2024}
}

@article{KLSGZH23,
  author = {Daniel Kang and Xuechen Li and Ion Stoica and Carlos Guestrin and Matei Zaharia and Tatsunori Hashimoto},
  title = {{Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks}},
  journal = {arxiv},
  year = {2023},
  eprint = {2302.05733},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@article{lv2024codechameleon,
  author = {Huijie Lv and Xiao Wang and Yuansen Zhang and Caishuang Huang and Shihan Dou and Junjie Ye and Tao Gui and Qi Zhang and Xuanjing Huang},
  title = {{CodeChameleon: Personalized Encryption Framework for Jailbreaking Large Language Models}},
  journal = {arxiv},
  year = {2024},
  eprint = {2402.16717},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR}
}

@inproceedings{petroni-etal-2019-language,
    author = {Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
    title = {Language models as knowledge bases?},
    booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
    pages = {2463--2473},
    year = {2019},
    publisher = {Association for Computational Linguistics},
    address = {Hong Kong, China},
    doi = {10.18653/v1/D19-1250}
}

@article{jiang-etal-2020-know,
    author = {Jiang, Zhengbao and Xu, Frank~F. and Araki, Jun and Neubig, Graham},
    title = {How can we know what language models know?},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {8},
    pages = {423--438},
    year = {2020},
    doi = {10.1162/tacl_a_00324}
}

@article{openai2025gpt41,
    author = {OpenAI, R},
    title = {Introducing GPT-4.1 in the API},
    journal = {https://openai.com/index/gpt-4-1/},
    year = {2025},
}

@article{grattafiori2024llama,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{yang2025qwen3,
  title={Qwen3 technical report},
  author={Yang, An and Li, Anfeng and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Gao, Chang and Huang, Chengen and Lv, Chenxu and others},
  journal={arXiv preprint arXiv:2505.09388},
  year={2025}
}


@article{openai2023gpt,
    author = {OpenAI, R},
    title = {Gpt-4 technical report},
    journal = {arXiv},
    year = {2023},
    eprint = {2303.08774},
    archiveprefix = {arXiv}
}

@article{zhao2023survey,
    author = {Zhao, Wayne~Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and et~al.},
    title = {A survey of large language models},
    journal = {arXiv},
    year = {2023},
    eprint = {2303.18223},
    archiveprefix = {arXiv}
}

@article{kadavath2022language,
    author = {Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and et~al.},
    title = {Language models (mostly) know what they know},
    journal = {arXiv},
    year = {2022},
    eprint = {2207.05221},
    archiveprefix = {arXiv}
}

@article{talmor-etal-2020-olmpics,
    author = {Talmor, Alon and Elazar, Yanai and Goldberg, Yoav and Berant, Jonathan},
    title = {o{LM}pics-on what language model pre-training captures},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {8},
    pages = {743--758},
    year = {2020},
    doi = {10.1162/tacl_a_00342}
}

@inproceedings{roberts-etal-2020-much,
    author = {Roberts, Adam and Raffel, Colin and Shazeer, Noam},
    title = {How much knowledge can you pack into the parameters of a language model?},
    booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    pages = {5418--5426},
    year = {2020},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    doi = {10.18653/v1/2020.emnlp-main.437}
}

@inproceedings{shin-etal-2020-autoprompt,
    author = {Shin, Taylor and Razeghi, Yasaman and Logan~IV, Robert~L. and Wallace, Eric and Singh, Sameer},
    title = {{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts},
    booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
    pages = {4222--4235},
    year = {2020},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    doi = {10.18653/v1/2020.emnlp-main.346}
}

@inproceedings{qin-eisner-2021-learning,
    author = {Qin, Guanghui and Eisner, Jason},
    title = {Learning how to ask: Querying {LM}s with mixtures of soft prompts},
    booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
    pages = {5203--5212},
    year = {2021},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    doi = {10.18653/v1/2021.naacl-main.410}
}

@inproceedings{zhong-etal-2021-factual,
    author = {Zhong, Zexuan and Friedman, Dan and Chen, Danqi},
    title = {Factual probing is [{MASK}]: Learning vs. learning to recall},
    booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
    pages = {5017--5033},
    year = {2021},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    doi = {10.18653/v1/2021.naacl-main.398}
}

@inproceedings{arora2022ask,
    author = {Arora, Simran and Narayan, Avanika and Chen, Mayee~F and Orr, Laurel and Guha, Neel and Bhatia, Kush and Chami, Ines and Re, Christopher},
    title = {Ask me anything: A simple strategy for prompting language models},
    booktitle = {The Eleventh International Conference on Learning Representations},
    year = {2022}
}

@inproceedings{maynez-etal-2020-faithfulness,
    author = {Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
    title = {On faithfulness and factuality in abstractive summarization},
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    pages = {1906--1919},
    year = {2020},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    doi = {10.18653/v1/2020.acl-main.173}
}

@inproceedings{lin-etal-2022-truthfulqa,
    author = {Lin, Stephanie and Hilton, Jacob and Evans, Owain},
    title = {{T}ruthful{QA}: Measuring how models mimic human falsehoods},
    booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    pages = {3214--3252},
    year = {2022},
    publisher = {Association for Computational Linguistics},
    address = {Dublin, Ireland},
    doi = {10.18653/v1/2022.acl-long.229}
}

@article{ji2023survey,
    author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye~Jin and Madotto, Andrea and Fung, Pascale},
    title = {Survey of hallucination in natural language generation},
    journal = {ACM Computing Surveys},
    volume = {55},
    number = {12},
    pages = {1--38},
    year = {2023}
}

@article{zheng2023does,
    author = {Zheng, Shen and Huang, Jie and Chang, Kevin Chen-Chuan},
    title = {Why does chatgpt fall short in providing truthful answers},
    journal = {arXiv},
    year = {2023},
    eprint = {2304.10513},
    archiveprefix = {arXiv}
}

@article{wysocka2023large,
    author = {Wysocka, Magdalena and Wysocki, Oskar and Delmas, Maxime and Mutel, Vincent and Freitas, Andre},
    title = {Large language models, scientific knowledge and factuality: A systematic analysis in antibiotic discovery},
    journal = {arXiv},
    year = {2023},
    eprint = {2305.17819},
    archiveprefix = {arXiv}
}

@article{manakul2023selfcheckgpt,
    author = {Manakul, Potsawee and Liusie, Adian and Gales, Mark~JF},
    title = {Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models},
    journal = {arXiv},
    year = {2023},
    eprint = {2303.08896},
    archiveprefix = {arXiv}
}

@article{li2023halueval,
    author = {Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne~Xin and Nie, Jian-Yun and Wen, Ji-Rong},
    title = {Halueval: A large-scale hallucination evaluation benchmark for large language models},
    journal = {arXiv},
    year = {2023}
}

@article{ren2023investigating,
    author = {Ren, Ruiyang and Wang, Yuhao and Qu, Yingqi and Zhao, Wayne~Xin and Liu, Jing and Tian, Hao and Wu, Hua and Wen, Ji-Rong and Wang, Haifeng},
    title = {Investigating the factual knowledge boundary of large language models with retrieval augmentation},
    journal = {arXiv},
    year = {2023},
    eprint = {2307.11019},
    archiveprefix = {arXiv}
}

@inproceedings{lee2022factuality,
    author = {Lee, Nayeon and Ping, Wei and Xu, Peng and Patwary, Mostofa and Fung, Pascale~N and Shoeybi, Mohammad and Catanzaro, Bryan},
    title = {Factuality enhanced language models for open-ended text generation},
    booktitle = {Advances in Neural Information Processing Systems},
    volume = {35},
    pages = {34586--34599},
    year = {2022}
}

@article{varshney2023stitch,
    author = {Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
    title = {A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
    journal = {arXiv},
    year = {2023},
    eprint = {2307.03987},
    archiveprefix = {arXiv}
}

@article{jiang2023disinformation,
    author = {Jiang, Bohan and Tan, Zhen and Nirmal, Ayushi and Liu, Huan},
    title = {Disinformation detection: An evolving challenge in the age of llms},
    journal = {arXiv},
    year = {2023},
    eprint = {2309.15847},
    archiveprefix = {arXiv}
}

@article{chen2023can,
    author = {Chen, Canyu and Shu, Kai},
    title = {Can llm-generated misinformation be detected?},
    journal = {arXiv},
    year = {2023},
    eprint = {2309.13788},
    archiveprefix = {arXiv}
}

@book{gass2015social,
    author = {Gass, Robert~H and Seiter, John~S},
    title = {Persuasion: Social inflence and compliance gaining},
    publisher = {Routledge},
    year = {2015}
}

@incollection{rashotte2007social,
    author = {Rashotte, Lisa},
    title = {Social influence},
    booktitle = {The Blackwell encyclopedia of sociology},
    year = {2007}
}

@article{siggelkow2007persuasion,
    author = {Siggelkow, Nicolaj},
    title = {Persuasion with case studies},
    journal = {Academy of management journal},
    volume = {50},
    number = {1},
    pages = {20--24},
    year = {2007}
}

@inproceedings{chawla2023social,
    author = {Chawla, Kushal and Shi, Weiyan and Zhang, Jingwen and Lucas, Gale and Yu, Zhou and Gratch, Jonathan},
    title = {Social influence dialogue systems: A survey of datasets and models for social influence tasks},
    booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
    pages = {750--766},
    year = {2023}
}

@article{chen2021persuasion,
    author = {Chen, Sijing and Xiao, Lu and Mao, Jin},
    title = {Persuasion strategies of misinformation-containing posts in the social media},
    journal = {Information Processing \& Management},
    volume = {58},
    number = {5},
    pages = {102665},
    year = {2021}
}

@article{ecker2022psychological,
    author = {Ecker, Ullrich~KH and Lewandowsky, Stephan and Cook, John and Schmid, Philipp and Fazio, Lisa~K and Brashier, Nadia and Kendeou, Panayiota and Vraga, Emily~K and Amazeen, Michelle~A},
    title = {The psychological drivers of misinformation belief and its resistance to correction},
    journal = {Nature Reviews Psychology},
    volume = {1},
    number = {1},
    pages = {13--29},
    year = {2022}
}

@article{rapp2002aristotle,
    author = {Rapp, Christof},
    title = {Aristotle’s rhetoric},
    journal = {The Stanford Encyclopedia of Philosophy},
    year = {2002},
    url = {http://seop.illc.uva.nl/entries/aristotle-rhetoric/}
}

@misc{3-appeal,
    author = {Gagich, Melanie and Zickel, Emilie and Pantuso, Terri},
    title = {Rhetorical appeals: Logos, pathos, and ethos defined},
    year = {2023},
    howpublished = {\url{https://pressbooks.library.tamu.edu/informedarguments/chapter/rhetorical-appeals-logos-pathos-and-ethos-defined/}}
}

@article{kidd2023ai,
    author = {Kidd, Celeste and Birhane, Abeba},
    title = {How ai can distort human beliefs},
    journal = {Science},
    volume = {380},
    number = {6651},
    pages = {1222--1223},
    year = {2023}
}

@article{xie2023adaptive,
    author = {Xie, Jian and Zhang, Kai and Chen, Jiangjie and Lou, Renze and Su, Yu},
    title = {Adaptive chameleon or stubborn sloth: Unraveling the behavior of large language models in knowledge conflicts},
    journal = {arXiv},
    year = {2023},
    eprint = {2305.13300},
    archiveprefix = {arXiv}
}

@article{shi2023trusting,
    author = {Shi, Weijia and Han, Xiaochuang and Lewis, Mike and Tsvetkov, Yulia and Zettlemoyer, Luke and Yih, Scott~Wen tau},
    title = {Trusting your evidence: Hallucinate less with context-aware decoding},
    journal = {arXiv},
    year = {2023},
    eprint = {2305.14739},
    archiveprefix = {arXiv}
}

@article{zhou2023context,
    author = {Zhou, Wenxuan and Zhang, Sheng and Poon, Hoifung and Chen, Muhao},
    title = {Context-faithful prompting for large language models},
    journal = {arXiv},
    year = {2023},
    eprint = {2303.11315},
    archiveprefix = {arXiv}
}

@inproceedings{kassner-schutze-2020-negated,
    author = {Kassner, Nora and Sch{\"u}tze, Hinrich},
    title = {Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly},
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    pages = {7811--7818},
    year = {2020},
    publisher = {Association for Computational Linguistics},
    address = {Online},
    doi = {10.18653/v1/2020.acl-main.698}
}

@inproceedings{zhao2021calibrate,
    author = {Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
    title = {Calibrate before use: Improving few-shot performance of language models},
    booktitle = {International Conference on Machine Learning},
    pages = {12697--12706},
    year = {2021},
    publisher = {PMLR}
}

@inproceedings{min-etal-2022-rethinking,
    author = {Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
    title = {Rethinking the role of demonstrations: What makes in-context learning work?},
    booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    pages = {11048--11064},
    year = {2022},
    publisher = {Association for Computational Linguistics},
    address = {Abu Dhabi, United Arab Emirates},
    doi = {10.18653/v1/2022.emnlp-main.759}
}

@article{pezeshkpour2023large,
    author = {Pezeshkpour, Pouya and Hruschka, Estevam},
    title = {Large language models sensitivity to the order of options in multiple-choice questions},
    journal = {arXiv},
    year = {2023},
    eprint = {2308.11483},
    archiveprefix = {arXiv}
}
@misc{verga2024replacingjudgesjuries,
      title={Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models}, 
      author={Pat Verga and Sebastian Hofstatter and Sophia Althammer and Yixuan Su and Aleksandra Piktus and Arkady Arkhangorodsky and Minjie Xu and Naomi White and Patrick Lewis},
      year={2024},
      eprint={2404.18796},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.18796}, 
}
@misc{chiu2024culturalteaming,
      title={CulturalTeaming: AI-Assisted Interactive Red-Teaming for Challenging LLMs' (Lack of) Multicultural Knowledge}, 
      author={Yu Ying Chiu and Liwei Jiang and Maria Antoniak and Chan Young Park and Shuyue Stella Li and Mehar Bhatia and Sahithya Ravi and Yulia Tsvetkov and Vered Shwartz and Yejin Choi},
      year={2024},
      eprint={2404.06664},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.06664}, 
}
@article{Rao2024NORMADAB,
  title={NORMAD: A Benchmark for Measuring the Cultural Adaptability of Large Language Models},
  author={Abhinav Rao and Akhila Yerukola and Vishwa Shah and Katharina Reinecke and Maarten Sap},
  journal={ArXiv},
  year={2024},
  volume={abs/2404.12464},
  url={https://api.semanticscholar.org/CorpusID:269282746}
}

@misc{shi2024culturebank,
      title={CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies}, 
      author={Weiyan Shi and Ryan Li and Yutong Zhang and Caleb Ziems and Chunhua yu and Raya Horesh and Rogério Abreu de Paula and Diyi Yang},
      year={2024},
      eprint={2404.15238},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.15238}, 
}
@article{Li2024CultureLLMIC,
  title={CultureLLM: Incorporating Cultural Differences into Large Language Models},
  author={Cheng Li and Mengzhou Chen and Jindong Wang and Sunayana Sitaram and Xing Xie},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.10946},
  url={https://api.semanticscholar.org/CorpusID:267750997}
}
@article{Fung2024MassivelyMK,
  title={Massively Multi-Cultural Knowledge Acquisition \& LM Benchmarking},
  author={Yi Ren Fung and Ruining Zhao and Jae Doo and Chenkai Sun and Heng Ji},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.09369},
  url={https://api.semanticscholar.org/CorpusID:267657749}
}
@article{Myung2024BLEnDAB,
  title={BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages},
  author={Jun-Hee Myung and Nayeon Lee and Yi Zhou and Jiho Jin and Rifki Afina Putri and Dimosthenis Antypas and Hsuvas Borkakoty and Eunsu Kim and Carla P{\'e}rez-Almendros and Abinew Ali Ayele and V'ictor Guti'errez-Basulto and Yazm'in Ib'anez-Garc'ia and Hwaran Lee and Shamsuddeen Hassan Muhammad and Kiwoong Park and Anar Rzayev and Nina White and Seid Muhie Yimam and Mohammad Taher Pilehvar and Nedjma Djouhra Ousidhoum and Jos{\'e} Camacho-Collados and Alice Oh},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.09948},
  url={https://api.semanticscholar.org/CorpusID:270521296}
}


@inproceedings{fan2024rag,
author = {Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
title = {A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6491–6501},
series = {KDD '24}
}


@inproceedings{xu-etal-2024-knowledge-conflicts,
    title = "Knowledge Conflicts for {LLM}s: A Survey",
    author = "Xu, Rongwu  and
      Qi, Zehan  and
      Guo, Zhijiang  and
      Wang, Cunxiang  and
      Wang, Hongru  and
      Zhang, Yue  and
      Xu, Wei",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.486/",
    doi = "10.18653/v1/2024.emnlp-main.486",
    pages = "8541--8565",
}


@inproceedings{xu-etal-2022-beyond,
    title = "Beyond Goldfish Memory: Long-Term Open-Domain Conversation",
    author = "Xu, Jing  and
      Szlam, Arthur  and
      Weston, Jason",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.356",
    doi = "10.18653/v1/2022.acl-long.356",
    pages = "5180--5197",
    abstract = "Despite recent improvements in open-domain dialogue models, state of the art models are trained and evaluated on short conversations with little context. In contrast, the long-term conversation setting has hardly been studied. In this work we collect and release a human-human dataset consisting of multiple chat sessions whereby the speaking partners learn about each other{'}s interests and discuss the things they have learnt from past sessions. We show how existing models trained on existing datasets perform poorly in this long-term conversation setting in both automatic and human evaluations, and we study long-context models that can perform much better. In particular, we find retrieval-augmented methods and methods with an ability to summarize and recall previous conversations outperform the standard encoder-decoder architectures currently considered state of the art.",
}

@misc{liu2024llmspersonaplug,
      title={LLMs + Persona-Plug = Personalized LLMs}, 
      author={Jiongnan Liu and Yutao Zhu and Shuting Wang and Xiaochi Wei and Erxue Min and Yu Lu and Shuaiqiang Wang and Dawei Yin and Zhicheng Dou},
      year={2024},
      eprint={2409.11901},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.11901}, 
}

@inproceedings{li-etal-2024-steerability,
    title = "The steerability of large language models toward data-driven personas",
    author = "Li, Junyi  and
      Peris, Charith  and
      Mehrabi, Ninareh  and
      Goyal, Palash  and
      Chang, Kai-Wei  and
      Galstyan, Aram  and
      Zemel, Richard  and
      Gupta, Rahul",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.405",
    doi = "10.18653/v1/2024.naacl-long.405",
    pages = "7290--7305",
    abstract = "Large language models (LLMs) are known to generate biased responses where the opinions of certain groups and populations are underrepresented. Here, we present a novel approach to achieve controllable generation of specific viewpoints using LLMs, that can be leveraged to produce multiple perspectives and to reflect the diverse opinions. Moving beyond the traditional reliance on demographics like age, gender, or party affiliation, we introduce a data-driven notion of persona grounded in collaborative filtering, which is defined as either a single individual or a cohort of individuals manifesting similar views across specific inquiries. As individuals in the same demographic group may have different personas, our data-driven persona definition allows for a more nuanced understanding of different (latent) social groups present in the population. In addition to this, we also explore an efficient method to steer LLMs toward the personas that we define. We show that our data-driven personas significantly enhance model steerability, with improvements of between 57{\%}-77{\%} over our best performing baselines.",
}
@misc{poddar2024personalizing,
      title={Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning}, 
      author={Sriyash Poddar and Yanming Wan and Hamish Ivison and Abhishek Gupta and Natasha Jaques},
      year={2024},
      eprint={2408.10075},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.10075}, 
}
@misc{mysore2023pearlpersonalizinglargelanguage,
      title={PEARL: Personalizing Large Language Model Writing Assistants with Generation-Calibrated Retrievers}, 
      author={Sheshera Mysore and Zhuoran Lu and Mengting Wan and Longqi Yang and Steve Menezes and Tina Baghaee and Emmanuel Barajas Gonzalez and Jennifer Neville and Tara Safavi},
      year={2023},
      eprint={2311.09180},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.09180}, 
}
@misc{keswani2024prosconsactivelearning,
      title={On the Pros and Cons of Active Learning for Moral Preference Elicitation}, 
      author={Vijay Keswani and Vincent Conitzer and Hoda Heidari and Jana Schaich Borg and Walter Sinnott-Armstrong},
      year={2024},
      eprint={2407.18889},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2407.18889}, 
}
@misc{zhang2024selfexploring,
      title={Self-Exploring Language Models: Active Preference Elicitation for Online Alignment}, 
      author={Shenao Zhang and Donghan Yu and Hiteshi Sharma and Ziyi Yang and Shuohang Wang and Hany Hassan and Zhaoran Wang},
      year={2024},
      eprint={2405.19332},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.19332}, 
}
@misc{ji2024activequeries,
      title={Reinforcement Learning from Human Feedback with Active Queries}, 
      author={Kaixuan Ji and Jiafan He and Quanquan Gu},
      year={2024},
      eprint={2402.09401},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.09401}, 
}
@misc{mehta2023sampleefficientreinforcementlearning,
      title={Sample Efficient Reinforcement Learning from Human Feedback via Active Exploration}, 
      author={Viraj Mehta and Vikramjeet Das and Ojash Neopane and Yijia Dai and Ilija Bogunovic and Jeff Schneider and Willie Neiswanger},
      year={2023},
      eprint={2312.00267},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.00267}, 
}
@misc{muldrew2024activepreferencelearning,
      title={Active Preference Learning for Large Language Models}, 
      author={William Muldrew and Peter Hayes and Mingtian Zhang and David Barber},
      year={2024},
      eprint={2402.08114},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.08114}, 
}
@misc{piriyakulkij2024activepreference,
      title={Active Preference Inference using Language Models and Probabilistic Reasoning}, 
      author={Wasu Top Piriyakulkij and Volodymyr Kuleshov and Kevin Ellis},
      year={2024},
      eprint={2312.12009},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.12009}, 
}

@misc{lee2024aligningthousandspreferencesmessage,
      title={Aligning to Thousands of Preferences via System Message Generalization}, 
      author={Seongyun Lee and Sue Hyun Park and Seungone Kim and Minjoon Seo},
      year={2024},
      eprint={2405.17977},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.17977}, 
}

@misc{chen2024reconcile,
      title={ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs}, 
      author={Justin Chih-Yao Chen and Swarnadeep Saha and Mohit Bansal},
      year={2024},
      eprint={2309.13007},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.13007}, 
}

@misc{sorensen2024roadmappluralisticalignment,
      title={A Roadmap to Pluralistic Alignment}, 
      author={Taylor Sorensen and Jared Moore and Jillian Fisher and Mitchell Gordon and Niloofar Mireshghallah and Christopher Michael Rytting and Andre Ye and Liwei Jiang and Ximing Lu and Nouha Dziri and Tim Althoff and Yejin Choi},
      year={2024},
      eprint={2402.05070},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.05070}, 
}
@misc{kirk2024prismalignment,
      title={The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models}, 
      author={Hannah Rose Kirk and Alexander Whitefield and Paul Röttger and Andrew Bean and Katerina Margatina and Juan Ciro and Rafael Mosquera and Max Bartolo and Adina Williams and He He and Bertie Vidgen and Scott A. Hale},
      year={2024},
      eprint={2404.16019},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.16019}, 
}
@misc{PERSONA2024,
      title={PERSONA: A Reproducible Testbed for Pluralistic Alignment}, 
      author={Louis Castricato and Nathan Lile and Rafael Rafailov and Jan-Philipp Fränken and Chelsea Finn},
      year={2024},
      eprint={2407.17387},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.17387}, 
}

@misc{sun2024personadb,
      title={Persona-DB: Efficient Large Language Model Personalization for Response Prediction with Collaborative Data Refinement}, 
      author={Chenkai Sun and Ke Yang and Revanth Gangi Reddy and Yi R. Fung and Hou Pong Chan and Kevin Small and ChengXiang Zhai and Heng Ji},
      year={2024},
      eprint={2402.11060},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.11060}, 
}

@misc{moon2024personabackstory,
      title={Virtual Personas for Language Models via an Anthology of Backstories}, 
      author={Suhong Moon and Marwa Abdulhai and Minwoo Kang and Joseph Suh and Widyadewi Soedarmadji and Eran Kohen Behar and David M. Chan},
      year={2024},
      eprint={2407.06576},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.06576}, 
}
@inproceedings{
kwok2024syntheticpersonas,
title={Evaluating Cultural Adaptability of a Large Language Model via Simulation of Synthetic Personas},
author={Louis Kwok and Michal Bravansky and Lewis Griffin},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=S4ZOkV1AHl}
}
@misc{serapiogarcía2023personalitytraits,
      title={Personality Traits in Large Language Models}, 
      author={Greg Serapio-García and Mustafa Safdari and Clément Crepy and Luning Sun and Stephen Fitz and Peter Romero and Marwa Abdulhai and Aleksandra Faust and Maja Matarić},
      year={2023},
      eprint={2307.00184},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.00184}, 
}

@inproceedings{
jiang2023evaluating,
title={Evaluating and Inducing Personality in Pre-trained Language Models},
author={Guangyuan Jiang and Manjie Xu and Song-Chun Zhu and Wenjuan Han and Chi Zhang and Yixin Zhu},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=I9xE1Jsjfx}
}

@misc{zhu2024personalityalignment,
      title={Personality Alignment of Large Language Models}, 
      author={Minjun Zhu and Linyi Yang and Yue Zhang},
      year={2024},
      eprint={2408.11779},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.11779}, 
}

@misc{chiu2024culturalbench,
      title={CulturalBench: a Robust, Diverse and Challenging Benchmark on Measuring the (Lack of) Cultural Knowledge of LLMs}, 
      author={Yu Ying Chiu and Liwei Jiang and Bill Yuchen Lin and Chan Young Park and Shuyue Stella Li and Sahithya Ravi and Mehar Bhatia and Maria Antoniak and Yulia Tsvetkov and Vered Shwartz and Yejin Choi},
      year={2024},
      eprint={2410.02677},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.02677}, 
}
@misc{personalizedsoup2023,
      title={Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging}, 
      author={Joel Jang and Seungone Kim and Bill Yuchen Lin and Yizhong Wang and Jack Hessel and Luke Zettlemoyer and Hannaneh Hajishirzi and Yejin Choi and Prithviraj Ammanabrolu},
      year={2023},
      eprint={2310.11564},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.11564}, 
}

@misc{han2024valueaugmentedsamplinglanguage,
      title={Value Augmented Sampling for Language Model Alignment and Personalization}, 
      author={Seungwook Han and Idan Shenfeld and Akash Srivastava and Yoon Kim and Pulkit Agrawal},
      year={2024},
      eprint={2405.06639},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.06639}, 
}

@article{kirk2024personalization,
  title={The benefits, risks and bounds of personalizing the alignment of large language models to individuals},
  author={Kirk, H.R. and Vidgen, B. and R{\"o}ttger, P. and others},
  journal={Nature Machine Intelligence},
  volume={6},
  pages={383--392},
  year={2024},
  publisher={Springer Nature},
  doi={10.1038/s42256-024-00820-y}
}
@misc{GlobalOpinionQA2024,
      title={Towards Measuring the Representation of Subjective Global Opinions in Language Models}, 
      author={Esin Durmus and Karina Nguyen and Thomas I. Liao and Nicholas Schiefer and Amanda Askell and Anton Bakhtin and Carol Chen and Zac Hatfield-Dodds and Danny Hernandez and Nicholas Joseph and Liane Lovitt and Sam McCandlish and Orowa Sikder and Alex Tamkin and Janel Thamkul and Jared Kaplan and Jack Clark and Deep Ganguli},
      year={2024},
      eprint={2306.16388},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.16388}, 
}

@inproceedings{chiang2024chatbot,
  title={Chatbot arena: an open platform for evaluating LLMs by human preference},
  author={Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios N and Li, Tianle and Li, Dacheng and Zhu, Banghua and Zhang, Hao and Jordan, Michael I and Gonzalez, Joseph E and others},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  pages={8359--8388},
  year={2024}
}

@article{rozen2024llms,
  title={Do LLMs have consistent values?},
  author={Rozen, Naama and Bezalel, Liat and Elidan, Gal and Globerson, Amir and Daniel, Ella},
  journal={arXiv preprint arXiv:2407.12878},
  year={2024}
}
@article{jin2025internal,
  title={Internal Value Alignment in Large Language Models through Controlled Value Vector Activation},
  author={Jin, Haoran and Li, Meng and Wang, Xiting and Xu, Zhihao and Huang, Minlie and Jia, Yantao and Lian, Defu},
  journal={arXiv preprint arXiv:2507.11316},
  year={2025}
}
@article{ganguli2023capacity,
  title={The capacity for moral self-correction in large language models},
  author={Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas I and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others},
  journal={arXiv preprint arXiv:2302.07459},
  year={2023}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}
@article{jiang2023personallm,
  author = {Jiang, Hang and Zhang, Xiajie and Cao, Xubo and Kabbara, Jad and Roy, Deb},
  year = {2023},
  title = {Personallm: Investigating the ability of gpt-3.5 to express personality traits and gender differences},
  journal = {arXiv},
}
@article{chakraborty2025structured,
  title={Structured Moral Reasoning in Language Models: A Value-Grounded Evaluation Framework},
  author={Chakraborty, Mohna and Wang, Lu and Jurgens, David},
  journal={arXiv preprint arXiv:2506.14948},
  year={2025}
}
@article{zhu2024personality,
  title={Personality alignment of large language models},
  author={Zhu, Minjun and Weng, Yixuan and Yang, Linyi and Zhang, Yue},
  journal={arXiv preprint arXiv:2408.11779},
  year={2024}
}
@article{tseng2024two,
  title={Two tales of persona in llms: A survey of role-playing and personalization},
  author={Tseng, Yu-Min and Huang, Yu-Chao and Hsiao, Teng-Yun and Chen, Wei-Lin and Huang, Chao-Wei and Meng, Yu and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2406.01171},
  year={2024}
}

@article{hadar2023plasticity,
  title={The plasticity of Chatgpt’s Mentalizing abilities: Personalization for personality structures},
  author={Hadar-Shoval, Dorit and Elyoseph, Zohar and Lvovsky, Maya},
  journal={Frontiers in Psychiatry},
  volume={14},
  pages={1234397},
  year={2023},
  publisher={Frontiers},
  doi={10.3389/fpsyt.2023.1234397},
}

@article{salewski2024context,
  title={In-context impersonation reveals Large Language Models' strengths and biases},
  author={Salewski, Leonard and Alaniz, Stephan and Rio-Torto, Isabel and Schulz, Eric and Akata, Zeynep},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY},
  doi={10.1145/3560815},
}




@inproceedings{lmopinion2023,
author = {Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
title = {Whose opinions do language models reflect?},
year = {2023},
publisher = {JMLR.org},
abstract = {Language models (LMs) are increasingly being used in open-ended contexts, where the opinions they reflect in response to subjective queries can have a profound impact, both on user satisfaction, and shaping the views of society at large. We put forth a quantitative framework to investigate the opinions reflected by LMs – by leveraging high-quality public opinion polls. Using this framework, we create OpinionQA, a dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular groups. Our analysis not only confirms prior observations about the left-leaning tendencies of some human feedback-tuned LMs, but also surfaces groups whose opinions are poorly reflected by current LMs (e.g., 65+ and widowed individuals).},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {1244},
numpages = {34},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@misc{ouyang2022rlhf,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{schulman2017ppo,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@misc{rafailov2024dpo,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@misc{bai2022hhrlhf,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.05862}, 
}
@inproceedings{ryan-etal-2024-unintended,
    title = "Unintended Impacts of {LLM} Alignment on Global Representation",
    author = "Ryan, Michael  and
      Held, William  and
      Yang, Diyi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.853",
    doi = "10.18653/v1/2024.acl-long.853",
    pages = "16121--16140",
    abstract = "Before being deployed for user-facing applications, developers align Large Language Models (LLMs) to user preferences through a variety of procedures, such as Reinforcement Learning From Human Feedback (RLHF) and Direct Preference Optimization (DPO). Current evaluations of these procedures focus on benchmarks of instruction following, reasoning, and truthfulness. However, human preferences are not universal, and aligning to specific preference sets may have unintended effects. We explore how alignment impacts performance along three axes of global representation: English dialects, multilingualism, and opinions from and about countries worldwide. Our results show that current alignment procedures create disparities between English dialects and global opinions. We find alignment improves capabilities in several languages. We conclude by discussing design decisions that led to these unintended impacts and recommendations for more equitable preference tuning. We make our code and data publicly available on Github.",
}

@misc{OpenAIModelSpec20250212,
  title = {{Model Spec}},
  author={OpenAI},
  year={2025},
  howpublished = {\url{https://model-spec.openai.com/2025-02-12.html}},
  note = {Published: 2025-02-12; Accessed: 2025-02-12}
}

@misc{ClaudeConstitution,
  title = {{Claude’s Constitution}},
  author={Anthropic},
  year={2024},
  howpublished = {\url{https://www.anthropic.com/news/claudes-constitution}},
  note = {Published: 2024-05-09; Accessed: 2024-05-19}
}

@misc{modularpluralism2024,
      title={Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration}, 
      author={Shangbin Feng and Taylor Sorensen and Yuhan Liu and Jillian Fisher and Chan Young Park and Yejin Choi and Yulia Tsvetkov},
      year={2024},
      eprint={2406.15951},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.15951}, 
}
@misc{lake2024distributionalovertonpluralisminvestigating,
      title={From Distributional to Overton Pluralism: Investigating Large Language Model Alignment}, 
      author={Thom Lake and Eunsol Choi and Greg Durrett},
      year={2024},
      eprint={2406.17692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17692}, 
}
@misc{chen2024palpluralisticalignmentframework,
      title={PAL: Pluralistic Alignment Framework for Learning from Heterogeneous Preferences}, 
      author={Daiwei Chen and Yi Chen and Aniket Rege and Ramya Korlakai Vinayak},
      year={2024},
      eprint={2406.08469},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.08469}, 
}

@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}

@article{wang2023aligning,
  title={Aligning large language models with human: A survey},
  author={Wang, Yufei and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Zeng, Xingshan and Huang, Wenyong and Shang, Lifeng and Jiang, Xin and Liu, Qun},
  journal={arXiv preprint arXiv:2307.12966},
  year={2023}
}



















































































@article{wang2025assessing,
  title={Assessing Judging Bias in Large Reasoning Models: An Empirical Study},
  author={Wang, Qian and Lou, Zhanzhi and Tang, Zhenheng and Chen, Nuo and Zhao, Xuandong and Zhang, Wenxuan and Song, Dawn and He, Bingsheng},
  journal={arXiv preprint arXiv:2504.09946},
  year={2025}
}



@article{wang2025limits,
  title={What Limits LLM-based Human Simulation: LLMs or Our Design?},
  author={Wang, Qian and Wu, Jiaying and Tang, Zhenheng and Luo, Bingqiao and Chen, Nuo and Chen, Wei and He, Bingsheng},
  journal={arXiv preprint arXiv:2501.08579},
  year={2025}
}

@article{tang2025dreamddp,
  title={DreamDDP: Accelerating Data Parallel Distributed LLM Training with Layer-wise Scheduled Partial Synchronization},
  author={Tang, Zhenheng and Tang, Zichen and Huang, Junlin and Pan, Xinglin and Yan, Rudan and Wang, Yuxin and Zhou, Amelie Chi and Shi, Shaohuai and Chu, Xiaowen and Li, Bo},
  journal={arXiv preprint arXiv:2502.11058},
  year={2025}
}

@inproceedings{zhu2025oraclekv,
title={Oracle{KV}: Oracle Guidance for Question-Independent {KV} Cache Compression},
author={Yuanbing Zhu and Zhenheng Tang and Xiang Liu and Ang Li and Bo Li and Xiaowen Chu and Bo Han},
booktitle={ICML 2025 Workshop on Long-Context Foundation Models},
year={2025},
url={https://openreview.net/forum?id=KHM2YOGgX9}
}

@inproceedings{weifan2025jailbreaklora,
title={JailbreakLo{RA}: Your Downloaded Lo{RA} from Sharing Platforms might be Unsafe},
author={Fanjunduo Wei and Zhenheng Tang and Rongfei Zeng and Tongliang Liu and Chengqi Zhang and Xiaowen Chu and Bo Han},
booktitle={ICML 2025 Workshop on Data in Generative Models - The Bad, the Ugly, and the Greats},
year={2025},
url={https://openreview.net/forum?id=RjaeiNswGh}
}

@inproceedings{tang2025ghost,
title={Ghost in the Cloud: Your Geo-Distributed Large Language Models Training is Easily Manipulated},
author={Zichen TANG and Zhenheng Tang and Gaoning Pan and Buhua Liu and Kunfeng Lai and Xiaowen Chu and Bo Li},
booktitle={ICML 2025 Workshop on Data in Generative Models - The Bad, the Ugly, and the Greats},
year={2025},
url={https://openreview.net/forum?id=dpDdqgfcTM}
}
@inproceedings{wang2025agenttaxo,
  title={AgentTaxo: Dissecting and Benchmarking Token Distribution of LLM Multi-Agent Systems},
  author={Wang, Qian and Tang, Zhenheng and Jiang, Zichen and Chen, Nuo and Wang, Tianyu and He, Bingsheng},
  booktitle={ICLR 2025 Workshop on Foundation Models in the Wild},
  year={2025},
}

@inproceedings{wang2025all,
  title={MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without Predefined SOPs},
  author={Wang, Qian and Wang, Tianyu and Tang, Zhenheng and Li, Qinbin and Chen, Nuo and Liang, Jingsheng and He, Bingsheng},
  booktitle={The 63rd Annual Meeting of the Association for Computational Linguistics},
  year={2025},
}


@inproceedings{xu-etal-2024-knowledge-conflicts,
    title = "Knowledge Conflicts for {LLM}s: A Survey",
    author = "Xu, Rongwu  and
      Qi, Zehan  and
      Guo, Zhijiang  and
      Wang, Cunxiang  and
      Wang, Hongru  and
      Zhang, Yue  and
      Xu, Wei",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
}

@article{lai2025mediatormemoryefficientllmmerging,
      title={Mediator: Memory-efficient LLM Merging with Less Parameter Conflicts and Uncertainty Based Routing}, 
      author={Kunfeng Lai and Zhenheng Tang and Xinglin Pan and Peijie Dong and Xiang Liu and Haolan Chen and Li Shen and Bo Li and Xiaowen Chu},
      year={2025},
      journal={arxiv preprint arXiv:2502.04411},
}

@article{liu2025llmsmaintainfundamentalabilities,
      title={Can LLMs Maintain Fundamental Abilities under KV Cache Compression?}, 
      author={Xiang Liu and Zhenheng Tang and Hong Chen and Peijie Dong and Zeyu Li and Xiuze Zhou and Bo Li and Xuming Hu and Xiaowen Chu},
      year={2025},
      journal={arxiv preprint arXiv:2502.01941},
}

@article{liu2025chunkkvsemanticpreservingkvcache,
      title={ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference}, 
      author={Xiang Liu and Zhenheng Tang and Peijie Dong and Zeyu Li and Bo Li and Xuming Hu and Xiaowen Chu},
      year={2025},
      journal={arxiv preprint arXiv:2502.00299},
}

@InProceedings{dong2025can,
title={Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression},
author={Dong, Peijie and Tang, Zhenheng and Liu, Xiang and Li, Lujun and Chu, Xiaowen and Li, Bo},
booktitle    = {Proceedings of the 42th International Conference on Machine Learning},
series       = {Proceedings of Machine Learning Research},
publisher    = {PMLR},
year={2025}
}






@inproceedings{
wang2025can,
title={Can {LLM} Simulations Truly Reflect Humanity? A Deep Dive},
author={Qian Wang and Zhenheng Tang and Bingsheng He},
booktitle={The Fourth Blogpost Track at ICLR 2025},
year={2025},
}

@inproceedings{
tang2025the,
title={The Lottery {LLM} Hypothesis, Rethinking What Abilities Should {LLM} Compression Preserve?},
author={Zhenheng Tang and Xiang Liu and Qian Wang and Peijie Dong and Bingsheng He and Xiaowen Chu and Bo Li},
booktitle={The Fourth Blogpost Track at ICLR 2025},
year={2025},
}


@article{tang2024fusionllmdecentralizedllmtraining,
      title={FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression}, 
      author={Zhenheng Tang and Xueze Kang and Yiming Yin and Xinglin Pan and Yuxin Wang and Xin He and Qiang Wang and Rongfei Zeng and Kaiyong Zhao and Shaohuai Shi and Amelie Chi Zhou and Bo Li and Bingsheng He and Xiaowen Chu},
      year={2024},
      journal={arxiv preprint arXiv:2410.12707},
}



@inproceedings{shen2025hotpluggable,
title={Hot-pluggable Federated Learning: Bridging General and Personalized {FL} via Dynamic Selection},
author={Lei Shen and Zhenheng Tang and Lijun Wu and Yonggang Zhang and Xiaowen Chu and Tao Qin and Bo Han},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
}


@inproceedings{tang2024fusefl,
title={FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion},
author={Zhenheng Tang and Yonggang Zhang and Peijie Dong and Yiu-ming Cheung and Amelie Chi Zhou and Bo Han and Xiaowen Chu},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
}



@inproceedings{shen2024hot,
title={Hot Pluggable Federated Learning},
author={Lei Shen and Zhenheng Tang and Lijun Wu and Yonggang Zhang and Xiaowen Chu and Tao Qin and Bo Han},
booktitle={International Workshop on Federated Foundation Models in Conjunction with NeurIPS 2024},
year={2024},
}







@inproceedings{BCRS-OPWA,
title={Bandwidth-Aware and Overlap-Weighted Compression for Communication-Efficient Federated Learning},
author={Tang, Zichen and Huang, Junlin and Yan, Rudan and Wang, Yuxin and Tang, Zhenheng and Shi, Shaohuai and Zhou, Amelie Chi and Chu, Xiaowen},
booktitle={53rd International Conference on Parallel Processing},
year={2024},
month = {12--15 August},
address = {Gotland, Sweden},
}

@inproceedings{tang2024fedimpro,
title={FedImpro: Measuring and Improving Client Update in Federated Learning},
author={Zhenheng Tang and Yonggang Zhang and Shaohuai Shi and Xinmei Tian and Tongliang Liu and Bo Han and Xiaowen Chu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@article{tang2023fusionai,
  title={FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs},
  author={Tang, Zhenheng and Wang, Yuxin and He, Xin and Zhang, Longteng and Pan, Xinglin and Wang, Qiang and Zeng, Rongfei and Zhao, Kaiyong and Shi, Shaohuai and He, Bingsheng and others},
  journal={arXiv preprint arXiv:2309.01172},
  year={2023}
}





@ARTICLE{GossipFL,
	author       = {Tang, Zhenheng and Shi, Shaohuai and Li, Bo and Chu, Xiaowen},
	journal      = {IEEE Transactions on Parallel and Distributed Systems},
	title        = {GossipFL: A Decentralized Federated Learning Framework with Sparsified and Adaptive Communication},
	year         = {2022},
	volume       = {},
	number       = {},
	pages        = {1--13},
}



@InProceedings{VHL,
	title        = {Virtual Homogeneity Learning: Defending against Data Heterogeneity in Federated Learning},
	author       = {Tang, Zhenheng and Zhang, Yonggang and Shi, Shaohuai and He, Xin and Han, Bo and Chu, Xiaowen},
	booktitle    = {Proceedings of the 39th International Conference on Machine Learning},
	pages        = {21111--21132},
	year         = {2022},
	volume       = {162},
	series       = {Proceedings of Machine Learning Research},
	month        = {17--23 Jul},
	publisher    = {PMLR}
}


@article{tang2023fedml,
  title={FedML Parrot: A Scalable Federated Learning System via Heterogeneity-aware Scheduling on Sequential and Hierarchical Training},
  author={Tang, Zhenheng and Chu, Xiaowen and Ran, Ryan Yide and Lee, Sunwoo and Shi, Shaohuai and Zhang, Yonggang and Wang, Yuxin and Liang, Alex Qiaozhong and Avestimehr, Salman and He, Chaoyang},
  journal={arXiv preprint arXiv:2303.01778},
  year={2023}
}

@inproceedings{tang2020communication,
	title        = {Communication-efficient decentralized learning with sparsification and adaptive peer selection},
	author       = {Tang, Zhenheng and Shi, Shaohuai and Chu, Xiaowen},
	booktitle    = {2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)},
	pages        = {1207--1208},
	organization = {IEEE}
}



@article{tang2020survey,
	title        = {Communication-efficient distributed deep learning: A comprehensive survey},
	author       = {Tang, Zhenheng and Shi, Shaohuai and Chu, Xiaowen and Wang, Wei and Li, Bo},
	journal      = {arXiv preprint arXiv:2003.06307},
	year         = {2020}
}

@inproceedings{tangdata,
	title        = {Data Resampling for Federated Learning with Non-IID Labels},
	author       = {Tang, Zhenheng and Hu, Zhikai and Shi, Shaohuai and Cheung, Yiu-ming and Jin, Yilun and Ren, Zhenghang and Chu, Xiaowen},
	booktitle    = {International Workshop on Federated and Transfer Learning for Data Sparsity and Confidentiality in Conjunction with IJCAI 2021(FTL-IJCAI'21)},
	year         = {2021}
}

@inproceedings{tangDVFS,
	author       = {Tang, Zhenheng and Wang, Yuxin and Wang, Qiang and Chu, Xiaowen},
	title        = {The Impact of GPU DVFS on the Energy and Performance of Deep Learning: An Empirical Study},
	year         = {2019},
	isbn         = {9781450366717},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	doi          = {10.1145/3307772.3328315},
	booktitle    = {Proceedings of the Tenth ACM International Conference on Future Energy Systems},
	pages        = {315–325},
	numpages     = {11},
	location     = {Phoenix, AZ, USA},
	series       = {e-Energy '19}
}



@ARTICLE{9275615,
	author       = {Shi, Shaohuai and Tang, Zhenheng and Chu, Xiaowen and Liu, Chengjian and Wang, Wei and Li, Bo},
	journal      = {IEEE Network},
	title        = {A Quantitative Survey of Communication Optimizations in Distributed Deep Learning},
	year         = {2021}
}


@inproceedings{shi2019distributed,
	title        = {A distributed synchronous SGD algorithm with global top-k sparsification for low bandwidth networks},
	author       = {Shi, Shaohuai and Wang, Qiang and Zhao, Kaiyong and Tang, Zhenheng and Wang, Yuxin and Huang, Xiang and Chu, Xiaowen},
	booktitle    = {2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)},
	pages        = {2238--2247},
	year         = {2019},
	organization = {IEEE}
}


@ARTICLE{he2021fedcv,
	title        = {FedCV: A Federated Learning Framework for Diverse Computer Vision Tasks},
	author       = {He, Chaoyang and Shah, Alay Dilipbhai and Tang, Zhenheng and Sivashunmugam, Di Fan1Adarshan Naiynar and Bhogaraju, Keerti and Shimpi, Mita and Shen, Li and Chu, Xiaowen and Soltanolkotabi, Mahdi and Avestimehr, Salman},
	journal      = {arXiv preprint arXiv:2111.11066},
	year         = {2021}
}


@inproceedings{shiGTOPKconvergence,
	title        = {A Convergence Analysis of Distributed SGD with Communication-Efficient Gradient Sparsification},
	author       = {Shi, Shaohuai and Zhao, Kaiyong and Wang, Qiang and Tang, Zhenheng and Chu, Xiaowen},
	booktitle    = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, {IJCAI-19}},
	publisher    = {International Joint Conferences on Artificial Intelligence Organization},
	pages        = {3411--3417},
	year         = {2019},
	month        = {7},
	doi          = {10.24963/ijcai.2019/473}
}

@article{shi2019layer,
	title        = {Layer-wise adaptive gradient sparsification for distributed deep learning with convergence guarantees},
	author       = {Shi, Shaohuai and Tang, Zhenheng and Wang, Qiang and Zhao, Kaiyong and Chu, Xiaowen},
	journal      = {arXiv preprint arXiv:1911.08727},
	year         = {2019}
}


@ARTICLE{9275615,
	author       = {Shi, Shaohuai and Tang, Zhenheng and Chu, Xiaowen and Liu, Chengjian and Wang, Wei and Li, Bo},
	journal      = {IEEE Network},
	title        = {A Quantitative Survey of Communication Optimizations in Distributed Deep Learning},
	year         = {2021}
}


@inproceedings{dong2024pruner,
  title={Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models},
  author={Dong, Peijie and Li, Lujun and Tang, Zhenheng and Liu, Xiang and Pan, Xinglin and Wang, Qiang and Chu, Xiaowen},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{dong2024stbllmbreaking1bitbarrier,
      title={STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs}, 
      author={Peijie Dong and Lujun Li and Yuedong Zhong and Dayou Du and Ruibo Fan and Yuhan Chen and Zhenheng Tang and Qiang Wang and Wei Xue and Yike Guo and Xiaowen Chu},
      year={2024},
      journal={arxiv preprint arXiv:2408.01803},
}



@InProceedings{Dong_2023_CVPR,
    author    = {Dong, Peijie and Li, Lujun and Wei, Zimian},
    title     = {DisWOT: Student Architecture Search for Distillation WithOut Training},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {11898-11908}
}


@InProceedings{Dong_2023_ICCV,
    author    = {Dong, Peijie and Li, Lujun and Wei, Zimian and Niu, Xin and Tian, Zhiliang and Pan, Hengyue},
    title     = {EMQ: Evolving Training-free Proxies for Automated Mixed Precision Quantization},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {17076-17086}
}





@inproceedings{Wang2024BurstGPTAR,
  title={BurstGPT: A Real-world Workload Dataset to Optimize LLM Serving Systems},
  author={Yuxin Wang and Yuhan Chen and Zeyu Li and Xueze Kang and Zhenheng Tang and Xin He and Rui Guo and Xin Wang and Qiang Wang and Amelie Chi Zhou and Xiaowen Chu},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:267334913}
}


@article{Wang2023ReliableAE,
  title={Reliable and Efficient In-Memory Fault Tolerance of Large Language Model Pretraining},
  author={Yuxin Wang and Shaohuai Shi and Xin He and Zhenheng Tang and Xinglin Pan and Yang Zheng and Xiaoyu Wu and Amelie Chi Zhou and Bingsheng He and Xiaowen Chu},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.12670},
  url={https://api.semanticscholar.org/CorpusID:264305601}
}



@article{shi2021towards,
  title={Towards scalable distributed training of deep learning on public cloud clusters},
  author={Shi, Shaohuai and Zhou, Xianhao and Song, Shutao and Wang, Xingyao and Zhu, Zilin and Huang, Xue and Jiang, Xinan and Zhou, Feihu and Guo, Zhenyu and Xie, Liqiang and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={3},
  pages={401--412},
  year={2021}
}



@article{shi2020quantitative,
  title={A quantitative survey of communication optimizations in distributed deep learning},
  author={Shi, Shaohuai and Tang, Zhenheng and Chu, Xiaowen and Liu, Chengjian and Wang, Wei and Li, Bo},
  journal={IEEE Network},
  volume={35},
  number={3},
  pages={230--237},
  year={2020},
  publisher={IEEE}
}





@article{wang2025emperor,
  title={The Emperor's New Chain-of-Thought: Probing Reasoning Theater Bias in Large Reasoning Models},
  author={Wang, Qian and Fan, Yubo and Tang, Zhenheng and Chen, Nuo and Wang, Wenxuan and He, Bingsheng},
  journal={arXiv preprint arXiv:2507.13758},
  year={2025}
}

@article{hua2025ride,
  title={Ride: Enhancing large language model alignment through restyled in-context learning demonstration exemplars},
  author={Hua, Yuncheng and Qu, Lizhen and Li, Zhuang and Xue, Hao and Salim, Flora D and Haffari, Gholamreza},
  journal={arXiv preprint arXiv:2502.11681},
  year={2025}
}


@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}











































































































































































































































































































































































